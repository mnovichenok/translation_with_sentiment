{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 52382,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.009545263640181741,
      "grad_norm": 0.3967459201812744,
      "learning_rate": 4.984123044811832e-05,
      "loss": 0.7188,
      "step": 500
    },
    {
      "epoch": 0.019090527280363482,
      "grad_norm": 0.43467724323272705,
      "learning_rate": 4.9682142720781946e-05,
      "loss": 0.1506,
      "step": 1000
    },
    {
      "epoch": 0.028635790920545225,
      "grad_norm": 0.3145085871219635,
      "learning_rate": 4.952305499344559e-05,
      "loss": 0.1377,
      "step": 1500
    },
    {
      "epoch": 0.038181054560726964,
      "grad_norm": 0.40244632959365845,
      "learning_rate": 4.9363967266109224e-05,
      "loss": 0.129,
      "step": 2000
    },
    {
      "epoch": 0.04772631820090871,
      "grad_norm": 0.28926190733909607,
      "learning_rate": 4.9204879538772866e-05,
      "loss": 0.1297,
      "step": 2500
    },
    {
      "epoch": 0.05727158184109045,
      "grad_norm": 0.28733524680137634,
      "learning_rate": 4.90457918114365e-05,
      "loss": 0.119,
      "step": 3000
    },
    {
      "epoch": 0.06681684548127219,
      "grad_norm": 0.2996608316898346,
      "learning_rate": 4.888670408410014e-05,
      "loss": 0.117,
      "step": 3500
    },
    {
      "epoch": 0.07636210912145393,
      "grad_norm": 0.25635650753974915,
      "learning_rate": 4.872761635676378e-05,
      "loss": 0.1187,
      "step": 4000
    },
    {
      "epoch": 0.08590737276163568,
      "grad_norm": 0.2947419583797455,
      "learning_rate": 4.856852862942741e-05,
      "loss": 0.1121,
      "step": 4500
    },
    {
      "epoch": 0.09545263640181742,
      "grad_norm": 0.23091022670269012,
      "learning_rate": 4.840944090209105e-05,
      "loss": 0.1094,
      "step": 5000
    },
    {
      "epoch": 0.10499790004199916,
      "grad_norm": 0.3410714864730835,
      "learning_rate": 4.825035317475469e-05,
      "loss": 0.1104,
      "step": 5500
    },
    {
      "epoch": 0.1145431636821809,
      "grad_norm": 0.433892160654068,
      "learning_rate": 4.809126544741833e-05,
      "loss": 0.1081,
      "step": 6000
    },
    {
      "epoch": 0.12408842732236264,
      "grad_norm": 0.2580411434173584,
      "learning_rate": 4.7932177720081965e-05,
      "loss": 0.1083,
      "step": 6500
    },
    {
      "epoch": 0.13363369096254438,
      "grad_norm": 0.30024999380111694,
      "learning_rate": 4.77730899927456e-05,
      "loss": 0.1062,
      "step": 7000
    },
    {
      "epoch": 0.14317895460272612,
      "grad_norm": 0.5067668557167053,
      "learning_rate": 4.761400226540924e-05,
      "loss": 0.1017,
      "step": 7500
    },
    {
      "epoch": 0.15272421824290786,
      "grad_norm": 0.23164573311805725,
      "learning_rate": 4.745491453807287e-05,
      "loss": 0.1027,
      "step": 8000
    },
    {
      "epoch": 0.16226948188308962,
      "grad_norm": 0.17279589176177979,
      "learning_rate": 4.7295826810736515e-05,
      "loss": 0.1032,
      "step": 8500
    },
    {
      "epoch": 0.17181474552327136,
      "grad_norm": 0.20861320197582245,
      "learning_rate": 4.713673908340015e-05,
      "loss": 0.0982,
      "step": 9000
    },
    {
      "epoch": 0.1813600091634531,
      "grad_norm": 0.19571901857852936,
      "learning_rate": 4.697765135606379e-05,
      "loss": 0.1007,
      "step": 9500
    },
    {
      "epoch": 0.19090527280363484,
      "grad_norm": 0.3558189868927002,
      "learning_rate": 4.681856362872743e-05,
      "loss": 0.1,
      "step": 10000
    },
    {
      "epoch": 0.20045053644381658,
      "grad_norm": 0.3635993003845215,
      "learning_rate": 4.6659475901391064e-05,
      "loss": 0.1013,
      "step": 10500
    },
    {
      "epoch": 0.20999580008399832,
      "grad_norm": 0.20137996971607208,
      "learning_rate": 4.6500388174054706e-05,
      "loss": 0.0991,
      "step": 11000
    },
    {
      "epoch": 0.21954106372418006,
      "grad_norm": 0.26977601647377014,
      "learning_rate": 4.6341300446718335e-05,
      "loss": 0.0977,
      "step": 11500
    },
    {
      "epoch": 0.2290863273643618,
      "grad_norm": 0.1668897271156311,
      "learning_rate": 4.618221271938198e-05,
      "loss": 0.0974,
      "step": 12000
    },
    {
      "epoch": 0.23863159100454354,
      "grad_norm": 0.2439572513103485,
      "learning_rate": 4.6023124992045613e-05,
      "loss": 0.0952,
      "step": 12500
    },
    {
      "epoch": 0.24817685464472528,
      "grad_norm": 0.25099828839302063,
      "learning_rate": 4.5864037264709256e-05,
      "loss": 0.0954,
      "step": 13000
    },
    {
      "epoch": 0.25772211828490704,
      "grad_norm": 0.2092849612236023,
      "learning_rate": 4.570494953737289e-05,
      "loss": 0.0928,
      "step": 13500
    },
    {
      "epoch": 0.26726738192508875,
      "grad_norm": 0.27368801832199097,
      "learning_rate": 4.554586181003653e-05,
      "loss": 0.0958,
      "step": 14000
    },
    {
      "epoch": 0.2768126455652705,
      "grad_norm": 0.20952405035495758,
      "learning_rate": 4.538677408270017e-05,
      "loss": 0.0963,
      "step": 14500
    },
    {
      "epoch": 0.28635790920545223,
      "grad_norm": 0.27603384852409363,
      "learning_rate": 4.5227686355363805e-05,
      "loss": 0.0948,
      "step": 15000
    },
    {
      "epoch": 0.295903172845634,
      "grad_norm": 0.18580947816371918,
      "learning_rate": 4.506859862802744e-05,
      "loss": 0.0912,
      "step": 15500
    },
    {
      "epoch": 0.3054484364858157,
      "grad_norm": 0.33631569147109985,
      "learning_rate": 4.490951090069108e-05,
      "loss": 0.0941,
      "step": 16000
    },
    {
      "epoch": 0.3149937001259975,
      "grad_norm": 0.20606017112731934,
      "learning_rate": 4.475042317335472e-05,
      "loss": 0.0918,
      "step": 16500
    },
    {
      "epoch": 0.32453896376617924,
      "grad_norm": 0.18784134089946747,
      "learning_rate": 4.4591335446018355e-05,
      "loss": 0.0913,
      "step": 17000
    },
    {
      "epoch": 0.33408422740636096,
      "grad_norm": 0.2746158838272095,
      "learning_rate": 4.443224771868199e-05,
      "loss": 0.092,
      "step": 17500
    },
    {
      "epoch": 0.3436294910465427,
      "grad_norm": 0.18396171927452087,
      "learning_rate": 4.427315999134563e-05,
      "loss": 0.0924,
      "step": 18000
    },
    {
      "epoch": 0.35317475468672443,
      "grad_norm": 0.3587726652622223,
      "learning_rate": 4.411407226400927e-05,
      "loss": 0.0897,
      "step": 18500
    },
    {
      "epoch": 0.3627200183269062,
      "grad_norm": 0.18625317513942719,
      "learning_rate": 4.3954984536672904e-05,
      "loss": 0.0911,
      "step": 19000
    },
    {
      "epoch": 0.3722652819670879,
      "grad_norm": 0.2798334062099457,
      "learning_rate": 4.3795896809336547e-05,
      "loss": 0.0901,
      "step": 19500
    },
    {
      "epoch": 0.3818105456072697,
      "grad_norm": 0.3080929219722748,
      "learning_rate": 4.363680908200018e-05,
      "loss": 0.0916,
      "step": 20000
    },
    {
      "epoch": 0.3913558092474514,
      "grad_norm": 0.34317436814308167,
      "learning_rate": 4.347772135466382e-05,
      "loss": 0.0891,
      "step": 20500
    },
    {
      "epoch": 0.40090107288763316,
      "grad_norm": 0.20105484127998352,
      "learning_rate": 4.3318633627327453e-05,
      "loss": 0.0875,
      "step": 21000
    },
    {
      "epoch": 0.4104463365278149,
      "grad_norm": 0.17725811898708344,
      "learning_rate": 4.3159545899991096e-05,
      "loss": 0.0891,
      "step": 21500
    },
    {
      "epoch": 0.41999160016799664,
      "grad_norm": 0.2345675230026245,
      "learning_rate": 4.300045817265473e-05,
      "loss": 0.0878,
      "step": 22000
    },
    {
      "epoch": 0.4295368638081784,
      "grad_norm": 0.22260113060474396,
      "learning_rate": 4.284137044531837e-05,
      "loss": 0.0866,
      "step": 22500
    },
    {
      "epoch": 0.4390821274483601,
      "grad_norm": 0.3178422451019287,
      "learning_rate": 4.268228271798201e-05,
      "loss": 0.0886,
      "step": 23000
    },
    {
      "epoch": 0.4486273910885419,
      "grad_norm": 0.19679924845695496,
      "learning_rate": 4.2523194990645645e-05,
      "loss": 0.0847,
      "step": 23500
    },
    {
      "epoch": 0.4581726547287236,
      "grad_norm": 0.3429501950740814,
      "learning_rate": 4.236410726330928e-05,
      "loss": 0.0847,
      "step": 24000
    },
    {
      "epoch": 0.46771791836890536,
      "grad_norm": 0.17271393537521362,
      "learning_rate": 4.220501953597292e-05,
      "loss": 0.0855,
      "step": 24500
    },
    {
      "epoch": 0.4772631820090871,
      "grad_norm": 0.2238561064004898,
      "learning_rate": 4.204593180863656e-05,
      "loss": 0.0858,
      "step": 25000
    },
    {
      "epoch": 0.48680844564926884,
      "grad_norm": 0.20591601729393005,
      "learning_rate": 4.1886844081300195e-05,
      "loss": 0.0862,
      "step": 25500
    },
    {
      "epoch": 0.49635370928945055,
      "grad_norm": 0.2843051254749298,
      "learning_rate": 4.172775635396383e-05,
      "loss": 0.0868,
      "step": 26000
    },
    {
      "epoch": 0.5058989729296323,
      "grad_norm": 0.20589976012706757,
      "learning_rate": 4.156866862662747e-05,
      "loss": 0.0845,
      "step": 26500
    },
    {
      "epoch": 0.5154442365698141,
      "grad_norm": 0.2269146591424942,
      "learning_rate": 4.140958089929111e-05,
      "loss": 0.0848,
      "step": 27000
    },
    {
      "epoch": 0.5249895002099958,
      "grad_norm": 0.3017174005508423,
      "learning_rate": 4.1250493171954744e-05,
      "loss": 0.0871,
      "step": 27500
    },
    {
      "epoch": 0.5345347638501775,
      "grad_norm": 0.2911338806152344,
      "learning_rate": 4.109140544461838e-05,
      "loss": 0.0834,
      "step": 28000
    },
    {
      "epoch": 0.5440800274903593,
      "grad_norm": 0.1467956006526947,
      "learning_rate": 4.093231771728202e-05,
      "loss": 0.0843,
      "step": 28500
    },
    {
      "epoch": 0.553625291130541,
      "grad_norm": 0.21365603804588318,
      "learning_rate": 4.077322998994566e-05,
      "loss": 0.0817,
      "step": 29000
    },
    {
      "epoch": 0.5631705547707228,
      "grad_norm": 0.17447097599506378,
      "learning_rate": 4.0614142262609294e-05,
      "loss": 0.084,
      "step": 29500
    },
    {
      "epoch": 0.5727158184109045,
      "grad_norm": 0.20828834176063538,
      "learning_rate": 4.0455054535272936e-05,
      "loss": 0.0857,
      "step": 30000
    },
    {
      "epoch": 0.5822610820510863,
      "grad_norm": 0.2936059236526489,
      "learning_rate": 4.029596680793657e-05,
      "loss": 0.0855,
      "step": 30500
    },
    {
      "epoch": 0.591806345691268,
      "grad_norm": 0.19555553793907166,
      "learning_rate": 4.013687908060021e-05,
      "loss": 0.0833,
      "step": 31000
    },
    {
      "epoch": 0.6013516093314497,
      "grad_norm": 0.15275605022907257,
      "learning_rate": 3.997779135326384e-05,
      "loss": 0.0822,
      "step": 31500
    },
    {
      "epoch": 0.6108968729716314,
      "grad_norm": 0.21279911696910858,
      "learning_rate": 3.9818703625927485e-05,
      "loss": 0.0809,
      "step": 32000
    },
    {
      "epoch": 0.6204421366118132,
      "grad_norm": 0.3032970130443573,
      "learning_rate": 3.965961589859112e-05,
      "loss": 0.0821,
      "step": 32500
    },
    {
      "epoch": 0.629987400251995,
      "grad_norm": 0.19154268503189087,
      "learning_rate": 3.950052817125476e-05,
      "loss": 0.0798,
      "step": 33000
    },
    {
      "epoch": 0.6395326638921767,
      "grad_norm": 0.22261978685855865,
      "learning_rate": 3.93414404439184e-05,
      "loss": 0.0825,
      "step": 33500
    },
    {
      "epoch": 0.6490779275323585,
      "grad_norm": 0.1713683009147644,
      "learning_rate": 3.9182352716582035e-05,
      "loss": 0.0781,
      "step": 34000
    },
    {
      "epoch": 0.6586231911725402,
      "grad_norm": 0.31008782982826233,
      "learning_rate": 3.902326498924567e-05,
      "loss": 0.0814,
      "step": 34500
    },
    {
      "epoch": 0.6681684548127219,
      "grad_norm": 0.2659643888473511,
      "learning_rate": 3.8864177261909306e-05,
      "loss": 0.0808,
      "step": 35000
    },
    {
      "epoch": 0.6777137184529036,
      "grad_norm": 0.2621211111545563,
      "learning_rate": 3.870508953457295e-05,
      "loss": 0.0797,
      "step": 35500
    },
    {
      "epoch": 0.6872589820930854,
      "grad_norm": 0.2544119954109192,
      "learning_rate": 3.8546001807236584e-05,
      "loss": 0.0808,
      "step": 36000
    },
    {
      "epoch": 0.6968042457332672,
      "grad_norm": 0.1980450451374054,
      "learning_rate": 3.838691407990022e-05,
      "loss": 0.0809,
      "step": 36500
    },
    {
      "epoch": 0.7063495093734489,
      "grad_norm": 0.2058003544807434,
      "learning_rate": 3.822782635256386e-05,
      "loss": 0.0807,
      "step": 37000
    },
    {
      "epoch": 0.7158947730136307,
      "grad_norm": 0.18141470849514008,
      "learning_rate": 3.80687386252275e-05,
      "loss": 0.0829,
      "step": 37500
    },
    {
      "epoch": 0.7254400366538124,
      "grad_norm": 0.21704831719398499,
      "learning_rate": 3.7909650897891134e-05,
      "loss": 0.0797,
      "step": 38000
    },
    {
      "epoch": 0.7349853002939941,
      "grad_norm": 0.22611741721630096,
      "learning_rate": 3.775056317055477e-05,
      "loss": 0.0803,
      "step": 38500
    },
    {
      "epoch": 0.7445305639341758,
      "grad_norm": 0.32307562232017517,
      "learning_rate": 3.759147544321841e-05,
      "loss": 0.0804,
      "step": 39000
    },
    {
      "epoch": 0.7540758275743576,
      "grad_norm": 0.193039670586586,
      "learning_rate": 3.743238771588205e-05,
      "loss": 0.0805,
      "step": 39500
    },
    {
      "epoch": 0.7636210912145394,
      "grad_norm": 0.15327805280685425,
      "learning_rate": 3.727329998854568e-05,
      "loss": 0.0796,
      "step": 40000
    },
    {
      "epoch": 0.7731663548547211,
      "grad_norm": 0.25463736057281494,
      "learning_rate": 3.7114212261209325e-05,
      "loss": 0.0792,
      "step": 40500
    },
    {
      "epoch": 0.7827116184949028,
      "grad_norm": 0.19682000577449799,
      "learning_rate": 3.695512453387296e-05,
      "loss": 0.0777,
      "step": 41000
    },
    {
      "epoch": 0.7922568821350846,
      "grad_norm": 0.21646250784397125,
      "learning_rate": 3.67960368065366e-05,
      "loss": 0.0802,
      "step": 41500
    },
    {
      "epoch": 0.8018021457752663,
      "grad_norm": 0.19079755246639252,
      "learning_rate": 3.663694907920023e-05,
      "loss": 0.0757,
      "step": 42000
    },
    {
      "epoch": 0.811347409415448,
      "grad_norm": 0.2823275327682495,
      "learning_rate": 3.6477861351863875e-05,
      "loss": 0.0785,
      "step": 42500
    },
    {
      "epoch": 0.8208926730556299,
      "grad_norm": 0.19812747836112976,
      "learning_rate": 3.631877362452751e-05,
      "loss": 0.08,
      "step": 43000
    },
    {
      "epoch": 0.8304379366958116,
      "grad_norm": 0.1864033341407776,
      "learning_rate": 3.6159685897191146e-05,
      "loss": 0.0784,
      "step": 43500
    },
    {
      "epoch": 0.8399832003359933,
      "grad_norm": 0.1652858853340149,
      "learning_rate": 3.600059816985479e-05,
      "loss": 0.0788,
      "step": 44000
    },
    {
      "epoch": 0.849528463976175,
      "grad_norm": 0.20059335231781006,
      "learning_rate": 3.5841510442518424e-05,
      "loss": 0.0783,
      "step": 44500
    },
    {
      "epoch": 0.8590737276163568,
      "grad_norm": 0.2118292897939682,
      "learning_rate": 3.568242271518206e-05,
      "loss": 0.0799,
      "step": 45000
    },
    {
      "epoch": 0.8686189912565385,
      "grad_norm": 0.20373347401618958,
      "learning_rate": 3.5523334987845695e-05,
      "loss": 0.0771,
      "step": 45500
    },
    {
      "epoch": 0.8781642548967202,
      "grad_norm": 0.16109108924865723,
      "learning_rate": 3.536424726050934e-05,
      "loss": 0.0789,
      "step": 46000
    },
    {
      "epoch": 0.8877095185369019,
      "grad_norm": 0.24914981424808502,
      "learning_rate": 3.5205159533172974e-05,
      "loss": 0.0775,
      "step": 46500
    },
    {
      "epoch": 0.8972547821770838,
      "grad_norm": 0.1902075558900833,
      "learning_rate": 3.504607180583661e-05,
      "loss": 0.0763,
      "step": 47000
    },
    {
      "epoch": 0.9068000458172655,
      "grad_norm": 0.2666968107223511,
      "learning_rate": 3.488698407850025e-05,
      "loss": 0.0776,
      "step": 47500
    },
    {
      "epoch": 0.9163453094574472,
      "grad_norm": 0.24693559110164642,
      "learning_rate": 3.472789635116389e-05,
      "loss": 0.0761,
      "step": 48000
    },
    {
      "epoch": 0.925890573097629,
      "grad_norm": 0.3535774350166321,
      "learning_rate": 3.456880862382752e-05,
      "loss": 0.0782,
      "step": 48500
    },
    {
      "epoch": 0.9354358367378107,
      "grad_norm": 0.2471315562725067,
      "learning_rate": 3.4409720896491165e-05,
      "loss": 0.0773,
      "step": 49000
    },
    {
      "epoch": 0.9449811003779924,
      "grad_norm": 0.20493420958518982,
      "learning_rate": 3.42506331691548e-05,
      "loss": 0.0777,
      "step": 49500
    },
    {
      "epoch": 0.9545263640181741,
      "grad_norm": 0.21647632122039795,
      "learning_rate": 3.409154544181844e-05,
      "loss": 0.0774,
      "step": 50000
    },
    {
      "epoch": 0.964071627658356,
      "grad_norm": 0.13765031099319458,
      "learning_rate": 3.393245771448207e-05,
      "loss": 0.0768,
      "step": 50500
    },
    {
      "epoch": 0.9736168912985377,
      "grad_norm": 0.2393442988395691,
      "learning_rate": 3.3773369987145715e-05,
      "loss": 0.0781,
      "step": 51000
    },
    {
      "epoch": 0.9831621549387194,
      "grad_norm": 0.19205887615680695,
      "learning_rate": 3.361428225980935e-05,
      "loss": 0.0778,
      "step": 51500
    },
    {
      "epoch": 0.9927074185789011,
      "grad_norm": 0.2679242193698883,
      "learning_rate": 3.3455194532472986e-05,
      "loss": 0.0749,
      "step": 52000
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.06205110624432564,
      "eval_runtime": 2962.2253,
      "eval_samples_per_second": 141.467,
      "eval_steps_per_second": 17.683,
      "step": 52382
    }
  ],
  "logging_steps": 500,
  "max_steps": 157146,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.4178948489412608e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
