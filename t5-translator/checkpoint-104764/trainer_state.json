{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 104764,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.009545263640181741,
      "grad_norm": 0.3967459201812744,
      "learning_rate": 4.984123044811832e-05,
      "loss": 0.7188,
      "step": 500
    },
    {
      "epoch": 0.019090527280363482,
      "grad_norm": 0.43467724323272705,
      "learning_rate": 4.9682142720781946e-05,
      "loss": 0.1506,
      "step": 1000
    },
    {
      "epoch": 0.028635790920545225,
      "grad_norm": 0.3145085871219635,
      "learning_rate": 4.952305499344559e-05,
      "loss": 0.1377,
      "step": 1500
    },
    {
      "epoch": 0.038181054560726964,
      "grad_norm": 0.40244632959365845,
      "learning_rate": 4.9363967266109224e-05,
      "loss": 0.129,
      "step": 2000
    },
    {
      "epoch": 0.04772631820090871,
      "grad_norm": 0.28926190733909607,
      "learning_rate": 4.9204879538772866e-05,
      "loss": 0.1297,
      "step": 2500
    },
    {
      "epoch": 0.05727158184109045,
      "grad_norm": 0.28733524680137634,
      "learning_rate": 4.90457918114365e-05,
      "loss": 0.119,
      "step": 3000
    },
    {
      "epoch": 0.06681684548127219,
      "grad_norm": 0.2996608316898346,
      "learning_rate": 4.888670408410014e-05,
      "loss": 0.117,
      "step": 3500
    },
    {
      "epoch": 0.07636210912145393,
      "grad_norm": 0.25635650753974915,
      "learning_rate": 4.872761635676378e-05,
      "loss": 0.1187,
      "step": 4000
    },
    {
      "epoch": 0.08590737276163568,
      "grad_norm": 0.2947419583797455,
      "learning_rate": 4.856852862942741e-05,
      "loss": 0.1121,
      "step": 4500
    },
    {
      "epoch": 0.09545263640181742,
      "grad_norm": 0.23091022670269012,
      "learning_rate": 4.840944090209105e-05,
      "loss": 0.1094,
      "step": 5000
    },
    {
      "epoch": 0.10499790004199916,
      "grad_norm": 0.3410714864730835,
      "learning_rate": 4.825035317475469e-05,
      "loss": 0.1104,
      "step": 5500
    },
    {
      "epoch": 0.1145431636821809,
      "grad_norm": 0.433892160654068,
      "learning_rate": 4.809126544741833e-05,
      "loss": 0.1081,
      "step": 6000
    },
    {
      "epoch": 0.12408842732236264,
      "grad_norm": 0.2580411434173584,
      "learning_rate": 4.7932177720081965e-05,
      "loss": 0.1083,
      "step": 6500
    },
    {
      "epoch": 0.13363369096254438,
      "grad_norm": 0.30024999380111694,
      "learning_rate": 4.77730899927456e-05,
      "loss": 0.1062,
      "step": 7000
    },
    {
      "epoch": 0.14317895460272612,
      "grad_norm": 0.5067668557167053,
      "learning_rate": 4.761400226540924e-05,
      "loss": 0.1017,
      "step": 7500
    },
    {
      "epoch": 0.15272421824290786,
      "grad_norm": 0.23164573311805725,
      "learning_rate": 4.745491453807287e-05,
      "loss": 0.1027,
      "step": 8000
    },
    {
      "epoch": 0.16226948188308962,
      "grad_norm": 0.17279589176177979,
      "learning_rate": 4.7295826810736515e-05,
      "loss": 0.1032,
      "step": 8500
    },
    {
      "epoch": 0.17181474552327136,
      "grad_norm": 0.20861320197582245,
      "learning_rate": 4.713673908340015e-05,
      "loss": 0.0982,
      "step": 9000
    },
    {
      "epoch": 0.1813600091634531,
      "grad_norm": 0.19571901857852936,
      "learning_rate": 4.697765135606379e-05,
      "loss": 0.1007,
      "step": 9500
    },
    {
      "epoch": 0.19090527280363484,
      "grad_norm": 0.3558189868927002,
      "learning_rate": 4.681856362872743e-05,
      "loss": 0.1,
      "step": 10000
    },
    {
      "epoch": 0.20045053644381658,
      "grad_norm": 0.3635993003845215,
      "learning_rate": 4.6659475901391064e-05,
      "loss": 0.1013,
      "step": 10500
    },
    {
      "epoch": 0.20999580008399832,
      "grad_norm": 0.20137996971607208,
      "learning_rate": 4.6500388174054706e-05,
      "loss": 0.0991,
      "step": 11000
    },
    {
      "epoch": 0.21954106372418006,
      "grad_norm": 0.26977601647377014,
      "learning_rate": 4.6341300446718335e-05,
      "loss": 0.0977,
      "step": 11500
    },
    {
      "epoch": 0.2290863273643618,
      "grad_norm": 0.1668897271156311,
      "learning_rate": 4.618221271938198e-05,
      "loss": 0.0974,
      "step": 12000
    },
    {
      "epoch": 0.23863159100454354,
      "grad_norm": 0.2439572513103485,
      "learning_rate": 4.6023124992045613e-05,
      "loss": 0.0952,
      "step": 12500
    },
    {
      "epoch": 0.24817685464472528,
      "grad_norm": 0.25099828839302063,
      "learning_rate": 4.5864037264709256e-05,
      "loss": 0.0954,
      "step": 13000
    },
    {
      "epoch": 0.25772211828490704,
      "grad_norm": 0.2092849612236023,
      "learning_rate": 4.570494953737289e-05,
      "loss": 0.0928,
      "step": 13500
    },
    {
      "epoch": 0.26726738192508875,
      "grad_norm": 0.27368801832199097,
      "learning_rate": 4.554586181003653e-05,
      "loss": 0.0958,
      "step": 14000
    },
    {
      "epoch": 0.2768126455652705,
      "grad_norm": 0.20952405035495758,
      "learning_rate": 4.538677408270017e-05,
      "loss": 0.0963,
      "step": 14500
    },
    {
      "epoch": 0.28635790920545223,
      "grad_norm": 0.27603384852409363,
      "learning_rate": 4.5227686355363805e-05,
      "loss": 0.0948,
      "step": 15000
    },
    {
      "epoch": 0.295903172845634,
      "grad_norm": 0.18580947816371918,
      "learning_rate": 4.506859862802744e-05,
      "loss": 0.0912,
      "step": 15500
    },
    {
      "epoch": 0.3054484364858157,
      "grad_norm": 0.33631569147109985,
      "learning_rate": 4.490951090069108e-05,
      "loss": 0.0941,
      "step": 16000
    },
    {
      "epoch": 0.3149937001259975,
      "grad_norm": 0.20606017112731934,
      "learning_rate": 4.475042317335472e-05,
      "loss": 0.0918,
      "step": 16500
    },
    {
      "epoch": 0.32453896376617924,
      "grad_norm": 0.18784134089946747,
      "learning_rate": 4.4591335446018355e-05,
      "loss": 0.0913,
      "step": 17000
    },
    {
      "epoch": 0.33408422740636096,
      "grad_norm": 0.2746158838272095,
      "learning_rate": 4.443224771868199e-05,
      "loss": 0.092,
      "step": 17500
    },
    {
      "epoch": 0.3436294910465427,
      "grad_norm": 0.18396171927452087,
      "learning_rate": 4.427315999134563e-05,
      "loss": 0.0924,
      "step": 18000
    },
    {
      "epoch": 0.35317475468672443,
      "grad_norm": 0.3587726652622223,
      "learning_rate": 4.411407226400927e-05,
      "loss": 0.0897,
      "step": 18500
    },
    {
      "epoch": 0.3627200183269062,
      "grad_norm": 0.18625317513942719,
      "learning_rate": 4.3954984536672904e-05,
      "loss": 0.0911,
      "step": 19000
    },
    {
      "epoch": 0.3722652819670879,
      "grad_norm": 0.2798334062099457,
      "learning_rate": 4.3795896809336547e-05,
      "loss": 0.0901,
      "step": 19500
    },
    {
      "epoch": 0.3818105456072697,
      "grad_norm": 0.3080929219722748,
      "learning_rate": 4.363680908200018e-05,
      "loss": 0.0916,
      "step": 20000
    },
    {
      "epoch": 0.3913558092474514,
      "grad_norm": 0.34317436814308167,
      "learning_rate": 4.347772135466382e-05,
      "loss": 0.0891,
      "step": 20500
    },
    {
      "epoch": 0.40090107288763316,
      "grad_norm": 0.20105484127998352,
      "learning_rate": 4.3318633627327453e-05,
      "loss": 0.0875,
      "step": 21000
    },
    {
      "epoch": 0.4104463365278149,
      "grad_norm": 0.17725811898708344,
      "learning_rate": 4.3159545899991096e-05,
      "loss": 0.0891,
      "step": 21500
    },
    {
      "epoch": 0.41999160016799664,
      "grad_norm": 0.2345675230026245,
      "learning_rate": 4.300045817265473e-05,
      "loss": 0.0878,
      "step": 22000
    },
    {
      "epoch": 0.4295368638081784,
      "grad_norm": 0.22260113060474396,
      "learning_rate": 4.284137044531837e-05,
      "loss": 0.0866,
      "step": 22500
    },
    {
      "epoch": 0.4390821274483601,
      "grad_norm": 0.3178422451019287,
      "learning_rate": 4.268228271798201e-05,
      "loss": 0.0886,
      "step": 23000
    },
    {
      "epoch": 0.4486273910885419,
      "grad_norm": 0.19679924845695496,
      "learning_rate": 4.2523194990645645e-05,
      "loss": 0.0847,
      "step": 23500
    },
    {
      "epoch": 0.4581726547287236,
      "grad_norm": 0.3429501950740814,
      "learning_rate": 4.236410726330928e-05,
      "loss": 0.0847,
      "step": 24000
    },
    {
      "epoch": 0.46771791836890536,
      "grad_norm": 0.17271393537521362,
      "learning_rate": 4.220501953597292e-05,
      "loss": 0.0855,
      "step": 24500
    },
    {
      "epoch": 0.4772631820090871,
      "grad_norm": 0.2238561064004898,
      "learning_rate": 4.204593180863656e-05,
      "loss": 0.0858,
      "step": 25000
    },
    {
      "epoch": 0.48680844564926884,
      "grad_norm": 0.20591601729393005,
      "learning_rate": 4.1886844081300195e-05,
      "loss": 0.0862,
      "step": 25500
    },
    {
      "epoch": 0.49635370928945055,
      "grad_norm": 0.2843051254749298,
      "learning_rate": 4.172775635396383e-05,
      "loss": 0.0868,
      "step": 26000
    },
    {
      "epoch": 0.5058989729296323,
      "grad_norm": 0.20589976012706757,
      "learning_rate": 4.156866862662747e-05,
      "loss": 0.0845,
      "step": 26500
    },
    {
      "epoch": 0.5154442365698141,
      "grad_norm": 0.2269146591424942,
      "learning_rate": 4.140958089929111e-05,
      "loss": 0.0848,
      "step": 27000
    },
    {
      "epoch": 0.5249895002099958,
      "grad_norm": 0.3017174005508423,
      "learning_rate": 4.1250493171954744e-05,
      "loss": 0.0871,
      "step": 27500
    },
    {
      "epoch": 0.5345347638501775,
      "grad_norm": 0.2911338806152344,
      "learning_rate": 4.109140544461838e-05,
      "loss": 0.0834,
      "step": 28000
    },
    {
      "epoch": 0.5440800274903593,
      "grad_norm": 0.1467956006526947,
      "learning_rate": 4.093231771728202e-05,
      "loss": 0.0843,
      "step": 28500
    },
    {
      "epoch": 0.553625291130541,
      "grad_norm": 0.21365603804588318,
      "learning_rate": 4.077322998994566e-05,
      "loss": 0.0817,
      "step": 29000
    },
    {
      "epoch": 0.5631705547707228,
      "grad_norm": 0.17447097599506378,
      "learning_rate": 4.0614142262609294e-05,
      "loss": 0.084,
      "step": 29500
    },
    {
      "epoch": 0.5727158184109045,
      "grad_norm": 0.20828834176063538,
      "learning_rate": 4.0455054535272936e-05,
      "loss": 0.0857,
      "step": 30000
    },
    {
      "epoch": 0.5822610820510863,
      "grad_norm": 0.2936059236526489,
      "learning_rate": 4.029596680793657e-05,
      "loss": 0.0855,
      "step": 30500
    },
    {
      "epoch": 0.591806345691268,
      "grad_norm": 0.19555553793907166,
      "learning_rate": 4.013687908060021e-05,
      "loss": 0.0833,
      "step": 31000
    },
    {
      "epoch": 0.6013516093314497,
      "grad_norm": 0.15275605022907257,
      "learning_rate": 3.997779135326384e-05,
      "loss": 0.0822,
      "step": 31500
    },
    {
      "epoch": 0.6108968729716314,
      "grad_norm": 0.21279911696910858,
      "learning_rate": 3.9818703625927485e-05,
      "loss": 0.0809,
      "step": 32000
    },
    {
      "epoch": 0.6204421366118132,
      "grad_norm": 0.3032970130443573,
      "learning_rate": 3.965961589859112e-05,
      "loss": 0.0821,
      "step": 32500
    },
    {
      "epoch": 0.629987400251995,
      "grad_norm": 0.19154268503189087,
      "learning_rate": 3.950052817125476e-05,
      "loss": 0.0798,
      "step": 33000
    },
    {
      "epoch": 0.6395326638921767,
      "grad_norm": 0.22261978685855865,
      "learning_rate": 3.93414404439184e-05,
      "loss": 0.0825,
      "step": 33500
    },
    {
      "epoch": 0.6490779275323585,
      "grad_norm": 0.1713683009147644,
      "learning_rate": 3.9182352716582035e-05,
      "loss": 0.0781,
      "step": 34000
    },
    {
      "epoch": 0.6586231911725402,
      "grad_norm": 0.31008782982826233,
      "learning_rate": 3.902326498924567e-05,
      "loss": 0.0814,
      "step": 34500
    },
    {
      "epoch": 0.6681684548127219,
      "grad_norm": 0.2659643888473511,
      "learning_rate": 3.8864177261909306e-05,
      "loss": 0.0808,
      "step": 35000
    },
    {
      "epoch": 0.6777137184529036,
      "grad_norm": 0.2621211111545563,
      "learning_rate": 3.870508953457295e-05,
      "loss": 0.0797,
      "step": 35500
    },
    {
      "epoch": 0.6872589820930854,
      "grad_norm": 0.2544119954109192,
      "learning_rate": 3.8546001807236584e-05,
      "loss": 0.0808,
      "step": 36000
    },
    {
      "epoch": 0.6968042457332672,
      "grad_norm": 0.1980450451374054,
      "learning_rate": 3.838691407990022e-05,
      "loss": 0.0809,
      "step": 36500
    },
    {
      "epoch": 0.7063495093734489,
      "grad_norm": 0.2058003544807434,
      "learning_rate": 3.822782635256386e-05,
      "loss": 0.0807,
      "step": 37000
    },
    {
      "epoch": 0.7158947730136307,
      "grad_norm": 0.18141470849514008,
      "learning_rate": 3.80687386252275e-05,
      "loss": 0.0829,
      "step": 37500
    },
    {
      "epoch": 0.7254400366538124,
      "grad_norm": 0.21704831719398499,
      "learning_rate": 3.7909650897891134e-05,
      "loss": 0.0797,
      "step": 38000
    },
    {
      "epoch": 0.7349853002939941,
      "grad_norm": 0.22611741721630096,
      "learning_rate": 3.775056317055477e-05,
      "loss": 0.0803,
      "step": 38500
    },
    {
      "epoch": 0.7445305639341758,
      "grad_norm": 0.32307562232017517,
      "learning_rate": 3.759147544321841e-05,
      "loss": 0.0804,
      "step": 39000
    },
    {
      "epoch": 0.7540758275743576,
      "grad_norm": 0.193039670586586,
      "learning_rate": 3.743238771588205e-05,
      "loss": 0.0805,
      "step": 39500
    },
    {
      "epoch": 0.7636210912145394,
      "grad_norm": 0.15327805280685425,
      "learning_rate": 3.727329998854568e-05,
      "loss": 0.0796,
      "step": 40000
    },
    {
      "epoch": 0.7731663548547211,
      "grad_norm": 0.25463736057281494,
      "learning_rate": 3.7114212261209325e-05,
      "loss": 0.0792,
      "step": 40500
    },
    {
      "epoch": 0.7827116184949028,
      "grad_norm": 0.19682000577449799,
      "learning_rate": 3.695512453387296e-05,
      "loss": 0.0777,
      "step": 41000
    },
    {
      "epoch": 0.7922568821350846,
      "grad_norm": 0.21646250784397125,
      "learning_rate": 3.67960368065366e-05,
      "loss": 0.0802,
      "step": 41500
    },
    {
      "epoch": 0.8018021457752663,
      "grad_norm": 0.19079755246639252,
      "learning_rate": 3.663694907920023e-05,
      "loss": 0.0757,
      "step": 42000
    },
    {
      "epoch": 0.811347409415448,
      "grad_norm": 0.2823275327682495,
      "learning_rate": 3.6477861351863875e-05,
      "loss": 0.0785,
      "step": 42500
    },
    {
      "epoch": 0.8208926730556299,
      "grad_norm": 0.19812747836112976,
      "learning_rate": 3.631877362452751e-05,
      "loss": 0.08,
      "step": 43000
    },
    {
      "epoch": 0.8304379366958116,
      "grad_norm": 0.1864033341407776,
      "learning_rate": 3.6159685897191146e-05,
      "loss": 0.0784,
      "step": 43500
    },
    {
      "epoch": 0.8399832003359933,
      "grad_norm": 0.1652858853340149,
      "learning_rate": 3.600059816985479e-05,
      "loss": 0.0788,
      "step": 44000
    },
    {
      "epoch": 0.849528463976175,
      "grad_norm": 0.20059335231781006,
      "learning_rate": 3.5841510442518424e-05,
      "loss": 0.0783,
      "step": 44500
    },
    {
      "epoch": 0.8590737276163568,
      "grad_norm": 0.2118292897939682,
      "learning_rate": 3.568242271518206e-05,
      "loss": 0.0799,
      "step": 45000
    },
    {
      "epoch": 0.8686189912565385,
      "grad_norm": 0.20373347401618958,
      "learning_rate": 3.5523334987845695e-05,
      "loss": 0.0771,
      "step": 45500
    },
    {
      "epoch": 0.8781642548967202,
      "grad_norm": 0.16109108924865723,
      "learning_rate": 3.536424726050934e-05,
      "loss": 0.0789,
      "step": 46000
    },
    {
      "epoch": 0.8877095185369019,
      "grad_norm": 0.24914981424808502,
      "learning_rate": 3.5205159533172974e-05,
      "loss": 0.0775,
      "step": 46500
    },
    {
      "epoch": 0.8972547821770838,
      "grad_norm": 0.1902075558900833,
      "learning_rate": 3.504607180583661e-05,
      "loss": 0.0763,
      "step": 47000
    },
    {
      "epoch": 0.9068000458172655,
      "grad_norm": 0.2666968107223511,
      "learning_rate": 3.488698407850025e-05,
      "loss": 0.0776,
      "step": 47500
    },
    {
      "epoch": 0.9163453094574472,
      "grad_norm": 0.24693559110164642,
      "learning_rate": 3.472789635116389e-05,
      "loss": 0.0761,
      "step": 48000
    },
    {
      "epoch": 0.925890573097629,
      "grad_norm": 0.3535774350166321,
      "learning_rate": 3.456880862382752e-05,
      "loss": 0.0782,
      "step": 48500
    },
    {
      "epoch": 0.9354358367378107,
      "grad_norm": 0.2471315562725067,
      "learning_rate": 3.4409720896491165e-05,
      "loss": 0.0773,
      "step": 49000
    },
    {
      "epoch": 0.9449811003779924,
      "grad_norm": 0.20493420958518982,
      "learning_rate": 3.42506331691548e-05,
      "loss": 0.0777,
      "step": 49500
    },
    {
      "epoch": 0.9545263640181741,
      "grad_norm": 0.21647632122039795,
      "learning_rate": 3.409154544181844e-05,
      "loss": 0.0774,
      "step": 50000
    },
    {
      "epoch": 0.964071627658356,
      "grad_norm": 0.13765031099319458,
      "learning_rate": 3.393245771448207e-05,
      "loss": 0.0768,
      "step": 50500
    },
    {
      "epoch": 0.9736168912985377,
      "grad_norm": 0.2393442988395691,
      "learning_rate": 3.3773369987145715e-05,
      "loss": 0.0781,
      "step": 51000
    },
    {
      "epoch": 0.9831621549387194,
      "grad_norm": 0.19205887615680695,
      "learning_rate": 3.361428225980935e-05,
      "loss": 0.0778,
      "step": 51500
    },
    {
      "epoch": 0.9927074185789011,
      "grad_norm": 0.2679242193698883,
      "learning_rate": 3.3455194532472986e-05,
      "loss": 0.0749,
      "step": 52000
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.06205110624432564,
      "eval_runtime": 2962.2253,
      "eval_samples_per_second": 141.467,
      "eval_steps_per_second": 17.683,
      "step": 52382
    },
    {
      "epoch": 1.002252682219083,
      "grad_norm": 0.15415294468402863,
      "learning_rate": 3.329610680513663e-05,
      "loss": 0.0754,
      "step": 52500
    },
    {
      "epoch": 1.0117979458592645,
      "grad_norm": 0.17333900928497314,
      "learning_rate": 3.3137019077800264e-05,
      "loss": 0.0768,
      "step": 53000
    },
    {
      "epoch": 1.0213432094994463,
      "grad_norm": 0.20886953175067902,
      "learning_rate": 3.29779313504639e-05,
      "loss": 0.0749,
      "step": 53500
    },
    {
      "epoch": 1.0308884731396282,
      "grad_norm": 0.2340811938047409,
      "learning_rate": 3.2818843623127536e-05,
      "loss": 0.0763,
      "step": 54000
    },
    {
      "epoch": 1.0404337367798098,
      "grad_norm": 0.20888637006282806,
      "learning_rate": 3.265975589579118e-05,
      "loss": 0.0738,
      "step": 54500
    },
    {
      "epoch": 1.0499790004199916,
      "grad_norm": 0.314496248960495,
      "learning_rate": 3.2500668168454814e-05,
      "loss": 0.0768,
      "step": 55000
    },
    {
      "epoch": 1.0595242640601734,
      "grad_norm": 0.1938590705394745,
      "learning_rate": 3.234158044111845e-05,
      "loss": 0.0735,
      "step": 55500
    },
    {
      "epoch": 1.069069527700355,
      "grad_norm": 0.24795274436473846,
      "learning_rate": 3.218249271378209e-05,
      "loss": 0.0742,
      "step": 56000
    },
    {
      "epoch": 1.0786147913405368,
      "grad_norm": 0.25025278329849243,
      "learning_rate": 3.202340498644573e-05,
      "loss": 0.0734,
      "step": 56500
    },
    {
      "epoch": 1.0881600549807187,
      "grad_norm": 0.21380215883255005,
      "learning_rate": 3.186431725910936e-05,
      "loss": 0.0741,
      "step": 57000
    },
    {
      "epoch": 1.0977053186209003,
      "grad_norm": 0.30150651931762695,
      "learning_rate": 3.1705229531773e-05,
      "loss": 0.0763,
      "step": 57500
    },
    {
      "epoch": 1.107250582261082,
      "grad_norm": 0.14467932283878326,
      "learning_rate": 3.154614180443664e-05,
      "loss": 0.0736,
      "step": 58000
    },
    {
      "epoch": 1.116795845901264,
      "grad_norm": 0.1959609091281891,
      "learning_rate": 3.138705407710028e-05,
      "loss": 0.0716,
      "step": 58500
    },
    {
      "epoch": 1.1263411095414455,
      "grad_norm": 0.19721999764442444,
      "learning_rate": 3.122796634976391e-05,
      "loss": 0.0746,
      "step": 59000
    },
    {
      "epoch": 1.1358863731816273,
      "grad_norm": 0.17729046940803528,
      "learning_rate": 3.1068878622427555e-05,
      "loss": 0.0748,
      "step": 59500
    },
    {
      "epoch": 1.145431636821809,
      "grad_norm": 0.20530292391777039,
      "learning_rate": 3.090979089509119e-05,
      "loss": 0.0746,
      "step": 60000
    },
    {
      "epoch": 1.1549769004619908,
      "grad_norm": 0.2908259630203247,
      "learning_rate": 3.075070316775483e-05,
      "loss": 0.0737,
      "step": 60500
    },
    {
      "epoch": 1.1645221641021726,
      "grad_norm": 0.1508679986000061,
      "learning_rate": 3.059161544041846e-05,
      "loss": 0.0702,
      "step": 61000
    },
    {
      "epoch": 1.1740674277423542,
      "grad_norm": 0.2367575615644455,
      "learning_rate": 3.0432527713082104e-05,
      "loss": 0.0706,
      "step": 61500
    },
    {
      "epoch": 1.183612691382536,
      "grad_norm": 0.2248425930738449,
      "learning_rate": 3.027343998574574e-05,
      "loss": 0.0715,
      "step": 62000
    },
    {
      "epoch": 1.1931579550227178,
      "grad_norm": 0.20640505850315094,
      "learning_rate": 3.011435225840938e-05,
      "loss": 0.0729,
      "step": 62500
    },
    {
      "epoch": 1.2027032186628994,
      "grad_norm": 0.19802680611610413,
      "learning_rate": 2.9955264531073018e-05,
      "loss": 0.0732,
      "step": 63000
    },
    {
      "epoch": 1.2122484823030812,
      "grad_norm": 0.25850316882133484,
      "learning_rate": 2.9796176803736654e-05,
      "loss": 0.0728,
      "step": 63500
    },
    {
      "epoch": 1.221793745943263,
      "grad_norm": 0.2642975151538849,
      "learning_rate": 2.9637089076400293e-05,
      "loss": 0.0742,
      "step": 64000
    },
    {
      "epoch": 1.2313390095834447,
      "grad_norm": 0.16998256742954254,
      "learning_rate": 2.947800134906393e-05,
      "loss": 0.0729,
      "step": 64500
    },
    {
      "epoch": 1.2408842732236265,
      "grad_norm": 0.15019632875919342,
      "learning_rate": 2.9318913621727567e-05,
      "loss": 0.0735,
      "step": 65000
    },
    {
      "epoch": 1.250429536863808,
      "grad_norm": 0.22129566967487335,
      "learning_rate": 2.9159825894391203e-05,
      "loss": 0.0717,
      "step": 65500
    },
    {
      "epoch": 1.25997480050399,
      "grad_norm": 0.18082797527313232,
      "learning_rate": 2.9000738167054842e-05,
      "loss": 0.0727,
      "step": 66000
    },
    {
      "epoch": 1.2695200641441717,
      "grad_norm": 0.1991959810256958,
      "learning_rate": 2.884165043971848e-05,
      "loss": 0.0704,
      "step": 66500
    },
    {
      "epoch": 1.2790653277843533,
      "grad_norm": 0.19181276857852936,
      "learning_rate": 2.8682562712382117e-05,
      "loss": 0.071,
      "step": 67000
    },
    {
      "epoch": 1.2886105914245352,
      "grad_norm": 0.17726436257362366,
      "learning_rate": 2.8523474985045756e-05,
      "loss": 0.0723,
      "step": 67500
    },
    {
      "epoch": 1.2981558550647168,
      "grad_norm": 0.2844589352607727,
      "learning_rate": 2.836438725770939e-05,
      "loss": 0.0709,
      "step": 68000
    },
    {
      "epoch": 1.3077011187048986,
      "grad_norm": 0.2432163655757904,
      "learning_rate": 2.820529953037303e-05,
      "loss": 0.0729,
      "step": 68500
    },
    {
      "epoch": 1.3172463823450804,
      "grad_norm": 0.17021647095680237,
      "learning_rate": 2.804621180303667e-05,
      "loss": 0.0717,
      "step": 69000
    },
    {
      "epoch": 1.3267916459852622,
      "grad_norm": 0.2416570633649826,
      "learning_rate": 2.7887124075700305e-05,
      "loss": 0.0734,
      "step": 69500
    },
    {
      "epoch": 1.3363369096254438,
      "grad_norm": 0.14522892236709595,
      "learning_rate": 2.7728036348363944e-05,
      "loss": 0.0722,
      "step": 70000
    },
    {
      "epoch": 1.3458821732656256,
      "grad_norm": 0.135999858379364,
      "learning_rate": 2.756894862102758e-05,
      "loss": 0.0692,
      "step": 70500
    },
    {
      "epoch": 1.3554274369058072,
      "grad_norm": 0.28028568625450134,
      "learning_rate": 2.740986089369122e-05,
      "loss": 0.0705,
      "step": 71000
    },
    {
      "epoch": 1.364972700545989,
      "grad_norm": 0.24267065525054932,
      "learning_rate": 2.7250773166354855e-05,
      "loss": 0.0707,
      "step": 71500
    },
    {
      "epoch": 1.374517964186171,
      "grad_norm": 0.14504334330558777,
      "learning_rate": 2.7091685439018494e-05,
      "loss": 0.0728,
      "step": 72000
    },
    {
      "epoch": 1.3840632278263525,
      "grad_norm": 0.18618689477443695,
      "learning_rate": 2.6932597711682133e-05,
      "loss": 0.0725,
      "step": 72500
    },
    {
      "epoch": 1.3936084914665343,
      "grad_norm": 0.3039734661579132,
      "learning_rate": 2.677350998434577e-05,
      "loss": 0.0711,
      "step": 73000
    },
    {
      "epoch": 1.403153755106716,
      "grad_norm": 0.20483805239200592,
      "learning_rate": 2.6614422257009407e-05,
      "loss": 0.0707,
      "step": 73500
    },
    {
      "epoch": 1.4126990187468977,
      "grad_norm": 0.19408264756202698,
      "learning_rate": 2.6455334529673043e-05,
      "loss": 0.071,
      "step": 74000
    },
    {
      "epoch": 1.4222442823870796,
      "grad_norm": 0.1710851788520813,
      "learning_rate": 2.6296246802336682e-05,
      "loss": 0.0721,
      "step": 74500
    },
    {
      "epoch": 1.4317895460272614,
      "grad_norm": 0.17207591235637665,
      "learning_rate": 2.6137159075000318e-05,
      "loss": 0.0719,
      "step": 75000
    },
    {
      "epoch": 1.441334809667443,
      "grad_norm": 0.14477847516536713,
      "learning_rate": 2.5978071347663957e-05,
      "loss": 0.0729,
      "step": 75500
    },
    {
      "epoch": 1.4508800733076248,
      "grad_norm": 0.22630733251571655,
      "learning_rate": 2.5818983620327596e-05,
      "loss": 0.0723,
      "step": 76000
    },
    {
      "epoch": 1.4604253369478064,
      "grad_norm": 0.23720672726631165,
      "learning_rate": 2.565989589299123e-05,
      "loss": 0.071,
      "step": 76500
    },
    {
      "epoch": 1.4699706005879882,
      "grad_norm": 0.2085345983505249,
      "learning_rate": 2.550080816565487e-05,
      "loss": 0.0704,
      "step": 77000
    },
    {
      "epoch": 1.47951586422817,
      "grad_norm": 0.2335543930530548,
      "learning_rate": 2.5341720438318506e-05,
      "loss": 0.0705,
      "step": 77500
    },
    {
      "epoch": 1.4890611278683517,
      "grad_norm": 0.20013993978500366,
      "learning_rate": 2.5182632710982145e-05,
      "loss": 0.0745,
      "step": 78000
    },
    {
      "epoch": 1.4986063915085335,
      "grad_norm": 0.18713338673114777,
      "learning_rate": 2.502354498364578e-05,
      "loss": 0.0708,
      "step": 78500
    },
    {
      "epoch": 1.508151655148715,
      "grad_norm": 0.23054322600364685,
      "learning_rate": 2.486445725630942e-05,
      "loss": 0.0735,
      "step": 79000
    },
    {
      "epoch": 1.517696918788897,
      "grad_norm": 0.15163318812847137,
      "learning_rate": 2.470536952897306e-05,
      "loss": 0.0705,
      "step": 79500
    },
    {
      "epoch": 1.5272421824290787,
      "grad_norm": 0.2042597383260727,
      "learning_rate": 2.4546281801636695e-05,
      "loss": 0.0697,
      "step": 80000
    },
    {
      "epoch": 1.5367874460692605,
      "grad_norm": 0.1413196176290512,
      "learning_rate": 2.4387194074300334e-05,
      "loss": 0.0722,
      "step": 80500
    },
    {
      "epoch": 1.5463327097094421,
      "grad_norm": 0.20042690634727478,
      "learning_rate": 2.4228106346963973e-05,
      "loss": 0.0713,
      "step": 81000
    },
    {
      "epoch": 1.555877973349624,
      "grad_norm": 0.14281877875328064,
      "learning_rate": 2.406901861962761e-05,
      "loss": 0.0685,
      "step": 81500
    },
    {
      "epoch": 1.5654232369898056,
      "grad_norm": 0.13086220622062683,
      "learning_rate": 2.3909930892291247e-05,
      "loss": 0.0712,
      "step": 82000
    },
    {
      "epoch": 1.5749685006299874,
      "grad_norm": 0.2397587150335312,
      "learning_rate": 2.3750843164954883e-05,
      "loss": 0.071,
      "step": 82500
    },
    {
      "epoch": 1.5845137642701692,
      "grad_norm": 0.23021221160888672,
      "learning_rate": 2.3591755437618522e-05,
      "loss": 0.0702,
      "step": 83000
    },
    {
      "epoch": 1.594059027910351,
      "grad_norm": 0.1667807251214981,
      "learning_rate": 2.3432667710282158e-05,
      "loss": 0.0724,
      "step": 83500
    },
    {
      "epoch": 1.6036042915505326,
      "grad_norm": 0.27981993556022644,
      "learning_rate": 2.3273579982945797e-05,
      "loss": 0.0688,
      "step": 84000
    },
    {
      "epoch": 1.6131495551907142,
      "grad_norm": 0.21935231983661652,
      "learning_rate": 2.3114492255609436e-05,
      "loss": 0.0699,
      "step": 84500
    },
    {
      "epoch": 1.622694818830896,
      "grad_norm": 0.302864670753479,
      "learning_rate": 2.295540452827307e-05,
      "loss": 0.0743,
      "step": 85000
    },
    {
      "epoch": 1.6322400824710779,
      "grad_norm": 0.12966373562812805,
      "learning_rate": 2.279631680093671e-05,
      "loss": 0.0694,
      "step": 85500
    },
    {
      "epoch": 1.6417853461112597,
      "grad_norm": 0.2647520899772644,
      "learning_rate": 2.2637229073600346e-05,
      "loss": 0.0703,
      "step": 86000
    },
    {
      "epoch": 1.6513306097514413,
      "grad_norm": 0.14113828539848328,
      "learning_rate": 2.2478141346263985e-05,
      "loss": 0.0701,
      "step": 86500
    },
    {
      "epoch": 1.6608758733916231,
      "grad_norm": 0.3463307321071625,
      "learning_rate": 2.231905361892762e-05,
      "loss": 0.0727,
      "step": 87000
    },
    {
      "epoch": 1.6704211370318047,
      "grad_norm": 0.2147776335477829,
      "learning_rate": 2.215996589159126e-05,
      "loss": 0.0685,
      "step": 87500
    },
    {
      "epoch": 1.6799664006719865,
      "grad_norm": 0.127351313829422,
      "learning_rate": 2.20008781642549e-05,
      "loss": 0.0695,
      "step": 88000
    },
    {
      "epoch": 1.6895116643121684,
      "grad_norm": 0.20107944309711456,
      "learning_rate": 2.1841790436918535e-05,
      "loss": 0.0686,
      "step": 88500
    },
    {
      "epoch": 1.6990569279523502,
      "grad_norm": 0.18361318111419678,
      "learning_rate": 2.1682702709582174e-05,
      "loss": 0.0693,
      "step": 89000
    },
    {
      "epoch": 1.7086021915925318,
      "grad_norm": 0.11645103245973587,
      "learning_rate": 2.152361498224581e-05,
      "loss": 0.0695,
      "step": 89500
    },
    {
      "epoch": 1.7181474552327134,
      "grad_norm": 0.28485146164894104,
      "learning_rate": 2.136452725490945e-05,
      "loss": 0.0712,
      "step": 90000
    },
    {
      "epoch": 1.7276927188728952,
      "grad_norm": 0.22761942446231842,
      "learning_rate": 2.1205439527573087e-05,
      "loss": 0.0684,
      "step": 90500
    },
    {
      "epoch": 1.737237982513077,
      "grad_norm": 0.29645392298698425,
      "learning_rate": 2.1046351800236723e-05,
      "loss": 0.0703,
      "step": 91000
    },
    {
      "epoch": 1.7467832461532589,
      "grad_norm": 0.16355185210704803,
      "learning_rate": 2.0887264072900362e-05,
      "loss": 0.0719,
      "step": 91500
    },
    {
      "epoch": 1.7563285097934405,
      "grad_norm": 0.22304940223693848,
      "learning_rate": 2.0728176345563998e-05,
      "loss": 0.0694,
      "step": 92000
    },
    {
      "epoch": 1.7658737734336223,
      "grad_norm": 0.3032442629337311,
      "learning_rate": 2.0569088618227637e-05,
      "loss": 0.0696,
      "step": 92500
    },
    {
      "epoch": 1.7754190370738039,
      "grad_norm": 0.2057262510061264,
      "learning_rate": 2.0410000890891273e-05,
      "loss": 0.0699,
      "step": 93000
    },
    {
      "epoch": 1.7849643007139857,
      "grad_norm": 0.15735207498073578,
      "learning_rate": 2.025091316355491e-05,
      "loss": 0.0688,
      "step": 93500
    },
    {
      "epoch": 1.7945095643541675,
      "grad_norm": 0.47712382674217224,
      "learning_rate": 2.009182543621855e-05,
      "loss": 0.0713,
      "step": 94000
    },
    {
      "epoch": 1.8040548279943494,
      "grad_norm": 0.23195771872997284,
      "learning_rate": 1.9932737708882186e-05,
      "loss": 0.0701,
      "step": 94500
    },
    {
      "epoch": 1.813600091634531,
      "grad_norm": 0.1799042522907257,
      "learning_rate": 1.9773649981545825e-05,
      "loss": 0.0702,
      "step": 95000
    },
    {
      "epoch": 1.8231453552747126,
      "grad_norm": 0.1479894369840622,
      "learning_rate": 1.961456225420946e-05,
      "loss": 0.0699,
      "step": 95500
    },
    {
      "epoch": 1.8326906189148944,
      "grad_norm": 0.23071804642677307,
      "learning_rate": 1.94554745268731e-05,
      "loss": 0.0678,
      "step": 96000
    },
    {
      "epoch": 1.8422358825550762,
      "grad_norm": 0.1679968386888504,
      "learning_rate": 1.9296386799536736e-05,
      "loss": 0.0699,
      "step": 96500
    },
    {
      "epoch": 1.851781146195258,
      "grad_norm": 0.20125307142734528,
      "learning_rate": 1.9137299072200378e-05,
      "loss": 0.0684,
      "step": 97000
    },
    {
      "epoch": 1.8613264098354396,
      "grad_norm": 0.2188422679901123,
      "learning_rate": 1.8978211344864014e-05,
      "loss": 0.0672,
      "step": 97500
    },
    {
      "epoch": 1.8708716734756214,
      "grad_norm": 0.17413827776908875,
      "learning_rate": 1.881912361752765e-05,
      "loss": 0.0698,
      "step": 98000
    },
    {
      "epoch": 1.880416937115803,
      "grad_norm": 0.2736130654811859,
      "learning_rate": 1.866003589019129e-05,
      "loss": 0.0674,
      "step": 98500
    },
    {
      "epoch": 1.8899622007559849,
      "grad_norm": 0.13052032887935638,
      "learning_rate": 1.8500948162854924e-05,
      "loss": 0.0681,
      "step": 99000
    },
    {
      "epoch": 1.8995074643961667,
      "grad_norm": 0.17302410304546356,
      "learning_rate": 1.8341860435518563e-05,
      "loss": 0.0702,
      "step": 99500
    },
    {
      "epoch": 1.9090527280363485,
      "grad_norm": 0.23504671454429626,
      "learning_rate": 1.81827727081822e-05,
      "loss": 0.0695,
      "step": 100000
    },
    {
      "epoch": 1.9185979916765301,
      "grad_norm": 0.30882078409194946,
      "learning_rate": 1.802368498084584e-05,
      "loss": 0.0682,
      "step": 100500
    },
    {
      "epoch": 1.9281432553167117,
      "grad_norm": 0.14945708215236664,
      "learning_rate": 1.7864597253509477e-05,
      "loss": 0.0684,
      "step": 101000
    },
    {
      "epoch": 1.9376885189568935,
      "grad_norm": 0.29783111810684204,
      "learning_rate": 1.7705509526173113e-05,
      "loss": 0.07,
      "step": 101500
    },
    {
      "epoch": 1.9472337825970754,
      "grad_norm": 0.21389110386371613,
      "learning_rate": 1.754642179883675e-05,
      "loss": 0.0681,
      "step": 102000
    },
    {
      "epoch": 1.9567790462372572,
      "grad_norm": 0.24669872224330902,
      "learning_rate": 1.7387334071500387e-05,
      "loss": 0.0684,
      "step": 102500
    },
    {
      "epoch": 1.9663243098774388,
      "grad_norm": 0.14676381647586823,
      "learning_rate": 1.7228246344164026e-05,
      "loss": 0.0677,
      "step": 103000
    },
    {
      "epoch": 1.9758695735176206,
      "grad_norm": 0.17150132358074188,
      "learning_rate": 1.7069158616827662e-05,
      "loss": 0.0649,
      "step": 103500
    },
    {
      "epoch": 1.9854148371578022,
      "grad_norm": 0.12601633369922638,
      "learning_rate": 1.6910070889491304e-05,
      "loss": 0.0686,
      "step": 104000
    },
    {
      "epoch": 1.994960100797984,
      "grad_norm": 0.2020021229982376,
      "learning_rate": 1.675098316215494e-05,
      "loss": 0.0688,
      "step": 104500
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.05590543523430824,
      "eval_runtime": 2194.7519,
      "eval_samples_per_second": 190.935,
      "eval_steps_per_second": 23.867,
      "step": 104764
    }
  ],
  "logging_steps": 500,
  "max_steps": 157146,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.8357896978825216e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
