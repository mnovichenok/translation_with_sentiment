{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 157146,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.009545263640181741,
      "grad_norm": 0.3967459201812744,
      "learning_rate": 4.984123044811832e-05,
      "loss": 0.7188,
      "step": 500
    },
    {
      "epoch": 0.019090527280363482,
      "grad_norm": 0.43467724323272705,
      "learning_rate": 4.9682142720781946e-05,
      "loss": 0.1506,
      "step": 1000
    },
    {
      "epoch": 0.028635790920545225,
      "grad_norm": 0.3145085871219635,
      "learning_rate": 4.952305499344559e-05,
      "loss": 0.1377,
      "step": 1500
    },
    {
      "epoch": 0.038181054560726964,
      "grad_norm": 0.40244632959365845,
      "learning_rate": 4.9363967266109224e-05,
      "loss": 0.129,
      "step": 2000
    },
    {
      "epoch": 0.04772631820090871,
      "grad_norm": 0.28926190733909607,
      "learning_rate": 4.9204879538772866e-05,
      "loss": 0.1297,
      "step": 2500
    },
    {
      "epoch": 0.05727158184109045,
      "grad_norm": 0.28733524680137634,
      "learning_rate": 4.90457918114365e-05,
      "loss": 0.119,
      "step": 3000
    },
    {
      "epoch": 0.06681684548127219,
      "grad_norm": 0.2996608316898346,
      "learning_rate": 4.888670408410014e-05,
      "loss": 0.117,
      "step": 3500
    },
    {
      "epoch": 0.07636210912145393,
      "grad_norm": 0.25635650753974915,
      "learning_rate": 4.872761635676378e-05,
      "loss": 0.1187,
      "step": 4000
    },
    {
      "epoch": 0.08590737276163568,
      "grad_norm": 0.2947419583797455,
      "learning_rate": 4.856852862942741e-05,
      "loss": 0.1121,
      "step": 4500
    },
    {
      "epoch": 0.09545263640181742,
      "grad_norm": 0.23091022670269012,
      "learning_rate": 4.840944090209105e-05,
      "loss": 0.1094,
      "step": 5000
    },
    {
      "epoch": 0.10499790004199916,
      "grad_norm": 0.3410714864730835,
      "learning_rate": 4.825035317475469e-05,
      "loss": 0.1104,
      "step": 5500
    },
    {
      "epoch": 0.1145431636821809,
      "grad_norm": 0.433892160654068,
      "learning_rate": 4.809126544741833e-05,
      "loss": 0.1081,
      "step": 6000
    },
    {
      "epoch": 0.12408842732236264,
      "grad_norm": 0.2580411434173584,
      "learning_rate": 4.7932177720081965e-05,
      "loss": 0.1083,
      "step": 6500
    },
    {
      "epoch": 0.13363369096254438,
      "grad_norm": 0.30024999380111694,
      "learning_rate": 4.77730899927456e-05,
      "loss": 0.1062,
      "step": 7000
    },
    {
      "epoch": 0.14317895460272612,
      "grad_norm": 0.5067668557167053,
      "learning_rate": 4.761400226540924e-05,
      "loss": 0.1017,
      "step": 7500
    },
    {
      "epoch": 0.15272421824290786,
      "grad_norm": 0.23164573311805725,
      "learning_rate": 4.745491453807287e-05,
      "loss": 0.1027,
      "step": 8000
    },
    {
      "epoch": 0.16226948188308962,
      "grad_norm": 0.17279589176177979,
      "learning_rate": 4.7295826810736515e-05,
      "loss": 0.1032,
      "step": 8500
    },
    {
      "epoch": 0.17181474552327136,
      "grad_norm": 0.20861320197582245,
      "learning_rate": 4.713673908340015e-05,
      "loss": 0.0982,
      "step": 9000
    },
    {
      "epoch": 0.1813600091634531,
      "grad_norm": 0.19571901857852936,
      "learning_rate": 4.697765135606379e-05,
      "loss": 0.1007,
      "step": 9500
    },
    {
      "epoch": 0.19090527280363484,
      "grad_norm": 0.3558189868927002,
      "learning_rate": 4.681856362872743e-05,
      "loss": 0.1,
      "step": 10000
    },
    {
      "epoch": 0.20045053644381658,
      "grad_norm": 0.3635993003845215,
      "learning_rate": 4.6659475901391064e-05,
      "loss": 0.1013,
      "step": 10500
    },
    {
      "epoch": 0.20999580008399832,
      "grad_norm": 0.20137996971607208,
      "learning_rate": 4.6500388174054706e-05,
      "loss": 0.0991,
      "step": 11000
    },
    {
      "epoch": 0.21954106372418006,
      "grad_norm": 0.26977601647377014,
      "learning_rate": 4.6341300446718335e-05,
      "loss": 0.0977,
      "step": 11500
    },
    {
      "epoch": 0.2290863273643618,
      "grad_norm": 0.1668897271156311,
      "learning_rate": 4.618221271938198e-05,
      "loss": 0.0974,
      "step": 12000
    },
    {
      "epoch": 0.23863159100454354,
      "grad_norm": 0.2439572513103485,
      "learning_rate": 4.6023124992045613e-05,
      "loss": 0.0952,
      "step": 12500
    },
    {
      "epoch": 0.24817685464472528,
      "grad_norm": 0.25099828839302063,
      "learning_rate": 4.5864037264709256e-05,
      "loss": 0.0954,
      "step": 13000
    },
    {
      "epoch": 0.25772211828490704,
      "grad_norm": 0.2092849612236023,
      "learning_rate": 4.570494953737289e-05,
      "loss": 0.0928,
      "step": 13500
    },
    {
      "epoch": 0.26726738192508875,
      "grad_norm": 0.27368801832199097,
      "learning_rate": 4.554586181003653e-05,
      "loss": 0.0958,
      "step": 14000
    },
    {
      "epoch": 0.2768126455652705,
      "grad_norm": 0.20952405035495758,
      "learning_rate": 4.538677408270017e-05,
      "loss": 0.0963,
      "step": 14500
    },
    {
      "epoch": 0.28635790920545223,
      "grad_norm": 0.27603384852409363,
      "learning_rate": 4.5227686355363805e-05,
      "loss": 0.0948,
      "step": 15000
    },
    {
      "epoch": 0.295903172845634,
      "grad_norm": 0.18580947816371918,
      "learning_rate": 4.506859862802744e-05,
      "loss": 0.0912,
      "step": 15500
    },
    {
      "epoch": 0.3054484364858157,
      "grad_norm": 0.33631569147109985,
      "learning_rate": 4.490951090069108e-05,
      "loss": 0.0941,
      "step": 16000
    },
    {
      "epoch": 0.3149937001259975,
      "grad_norm": 0.20606017112731934,
      "learning_rate": 4.475042317335472e-05,
      "loss": 0.0918,
      "step": 16500
    },
    {
      "epoch": 0.32453896376617924,
      "grad_norm": 0.18784134089946747,
      "learning_rate": 4.4591335446018355e-05,
      "loss": 0.0913,
      "step": 17000
    },
    {
      "epoch": 0.33408422740636096,
      "grad_norm": 0.2746158838272095,
      "learning_rate": 4.443224771868199e-05,
      "loss": 0.092,
      "step": 17500
    },
    {
      "epoch": 0.3436294910465427,
      "grad_norm": 0.18396171927452087,
      "learning_rate": 4.427315999134563e-05,
      "loss": 0.0924,
      "step": 18000
    },
    {
      "epoch": 0.35317475468672443,
      "grad_norm": 0.3587726652622223,
      "learning_rate": 4.411407226400927e-05,
      "loss": 0.0897,
      "step": 18500
    },
    {
      "epoch": 0.3627200183269062,
      "grad_norm": 0.18625317513942719,
      "learning_rate": 4.3954984536672904e-05,
      "loss": 0.0911,
      "step": 19000
    },
    {
      "epoch": 0.3722652819670879,
      "grad_norm": 0.2798334062099457,
      "learning_rate": 4.3795896809336547e-05,
      "loss": 0.0901,
      "step": 19500
    },
    {
      "epoch": 0.3818105456072697,
      "grad_norm": 0.3080929219722748,
      "learning_rate": 4.363680908200018e-05,
      "loss": 0.0916,
      "step": 20000
    },
    {
      "epoch": 0.3913558092474514,
      "grad_norm": 0.34317436814308167,
      "learning_rate": 4.347772135466382e-05,
      "loss": 0.0891,
      "step": 20500
    },
    {
      "epoch": 0.40090107288763316,
      "grad_norm": 0.20105484127998352,
      "learning_rate": 4.3318633627327453e-05,
      "loss": 0.0875,
      "step": 21000
    },
    {
      "epoch": 0.4104463365278149,
      "grad_norm": 0.17725811898708344,
      "learning_rate": 4.3159545899991096e-05,
      "loss": 0.0891,
      "step": 21500
    },
    {
      "epoch": 0.41999160016799664,
      "grad_norm": 0.2345675230026245,
      "learning_rate": 4.300045817265473e-05,
      "loss": 0.0878,
      "step": 22000
    },
    {
      "epoch": 0.4295368638081784,
      "grad_norm": 0.22260113060474396,
      "learning_rate": 4.284137044531837e-05,
      "loss": 0.0866,
      "step": 22500
    },
    {
      "epoch": 0.4390821274483601,
      "grad_norm": 0.3178422451019287,
      "learning_rate": 4.268228271798201e-05,
      "loss": 0.0886,
      "step": 23000
    },
    {
      "epoch": 0.4486273910885419,
      "grad_norm": 0.19679924845695496,
      "learning_rate": 4.2523194990645645e-05,
      "loss": 0.0847,
      "step": 23500
    },
    {
      "epoch": 0.4581726547287236,
      "grad_norm": 0.3429501950740814,
      "learning_rate": 4.236410726330928e-05,
      "loss": 0.0847,
      "step": 24000
    },
    {
      "epoch": 0.46771791836890536,
      "grad_norm": 0.17271393537521362,
      "learning_rate": 4.220501953597292e-05,
      "loss": 0.0855,
      "step": 24500
    },
    {
      "epoch": 0.4772631820090871,
      "grad_norm": 0.2238561064004898,
      "learning_rate": 4.204593180863656e-05,
      "loss": 0.0858,
      "step": 25000
    },
    {
      "epoch": 0.48680844564926884,
      "grad_norm": 0.20591601729393005,
      "learning_rate": 4.1886844081300195e-05,
      "loss": 0.0862,
      "step": 25500
    },
    {
      "epoch": 0.49635370928945055,
      "grad_norm": 0.2843051254749298,
      "learning_rate": 4.172775635396383e-05,
      "loss": 0.0868,
      "step": 26000
    },
    {
      "epoch": 0.5058989729296323,
      "grad_norm": 0.20589976012706757,
      "learning_rate": 4.156866862662747e-05,
      "loss": 0.0845,
      "step": 26500
    },
    {
      "epoch": 0.5154442365698141,
      "grad_norm": 0.2269146591424942,
      "learning_rate": 4.140958089929111e-05,
      "loss": 0.0848,
      "step": 27000
    },
    {
      "epoch": 0.5249895002099958,
      "grad_norm": 0.3017174005508423,
      "learning_rate": 4.1250493171954744e-05,
      "loss": 0.0871,
      "step": 27500
    },
    {
      "epoch": 0.5345347638501775,
      "grad_norm": 0.2911338806152344,
      "learning_rate": 4.109140544461838e-05,
      "loss": 0.0834,
      "step": 28000
    },
    {
      "epoch": 0.5440800274903593,
      "grad_norm": 0.1467956006526947,
      "learning_rate": 4.093231771728202e-05,
      "loss": 0.0843,
      "step": 28500
    },
    {
      "epoch": 0.553625291130541,
      "grad_norm": 0.21365603804588318,
      "learning_rate": 4.077322998994566e-05,
      "loss": 0.0817,
      "step": 29000
    },
    {
      "epoch": 0.5631705547707228,
      "grad_norm": 0.17447097599506378,
      "learning_rate": 4.0614142262609294e-05,
      "loss": 0.084,
      "step": 29500
    },
    {
      "epoch": 0.5727158184109045,
      "grad_norm": 0.20828834176063538,
      "learning_rate": 4.0455054535272936e-05,
      "loss": 0.0857,
      "step": 30000
    },
    {
      "epoch": 0.5822610820510863,
      "grad_norm": 0.2936059236526489,
      "learning_rate": 4.029596680793657e-05,
      "loss": 0.0855,
      "step": 30500
    },
    {
      "epoch": 0.591806345691268,
      "grad_norm": 0.19555553793907166,
      "learning_rate": 4.013687908060021e-05,
      "loss": 0.0833,
      "step": 31000
    },
    {
      "epoch": 0.6013516093314497,
      "grad_norm": 0.15275605022907257,
      "learning_rate": 3.997779135326384e-05,
      "loss": 0.0822,
      "step": 31500
    },
    {
      "epoch": 0.6108968729716314,
      "grad_norm": 0.21279911696910858,
      "learning_rate": 3.9818703625927485e-05,
      "loss": 0.0809,
      "step": 32000
    },
    {
      "epoch": 0.6204421366118132,
      "grad_norm": 0.3032970130443573,
      "learning_rate": 3.965961589859112e-05,
      "loss": 0.0821,
      "step": 32500
    },
    {
      "epoch": 0.629987400251995,
      "grad_norm": 0.19154268503189087,
      "learning_rate": 3.950052817125476e-05,
      "loss": 0.0798,
      "step": 33000
    },
    {
      "epoch": 0.6395326638921767,
      "grad_norm": 0.22261978685855865,
      "learning_rate": 3.93414404439184e-05,
      "loss": 0.0825,
      "step": 33500
    },
    {
      "epoch": 0.6490779275323585,
      "grad_norm": 0.1713683009147644,
      "learning_rate": 3.9182352716582035e-05,
      "loss": 0.0781,
      "step": 34000
    },
    {
      "epoch": 0.6586231911725402,
      "grad_norm": 0.31008782982826233,
      "learning_rate": 3.902326498924567e-05,
      "loss": 0.0814,
      "step": 34500
    },
    {
      "epoch": 0.6681684548127219,
      "grad_norm": 0.2659643888473511,
      "learning_rate": 3.8864177261909306e-05,
      "loss": 0.0808,
      "step": 35000
    },
    {
      "epoch": 0.6777137184529036,
      "grad_norm": 0.2621211111545563,
      "learning_rate": 3.870508953457295e-05,
      "loss": 0.0797,
      "step": 35500
    },
    {
      "epoch": 0.6872589820930854,
      "grad_norm": 0.2544119954109192,
      "learning_rate": 3.8546001807236584e-05,
      "loss": 0.0808,
      "step": 36000
    },
    {
      "epoch": 0.6968042457332672,
      "grad_norm": 0.1980450451374054,
      "learning_rate": 3.838691407990022e-05,
      "loss": 0.0809,
      "step": 36500
    },
    {
      "epoch": 0.7063495093734489,
      "grad_norm": 0.2058003544807434,
      "learning_rate": 3.822782635256386e-05,
      "loss": 0.0807,
      "step": 37000
    },
    {
      "epoch": 0.7158947730136307,
      "grad_norm": 0.18141470849514008,
      "learning_rate": 3.80687386252275e-05,
      "loss": 0.0829,
      "step": 37500
    },
    {
      "epoch": 0.7254400366538124,
      "grad_norm": 0.21704831719398499,
      "learning_rate": 3.7909650897891134e-05,
      "loss": 0.0797,
      "step": 38000
    },
    {
      "epoch": 0.7349853002939941,
      "grad_norm": 0.22611741721630096,
      "learning_rate": 3.775056317055477e-05,
      "loss": 0.0803,
      "step": 38500
    },
    {
      "epoch": 0.7445305639341758,
      "grad_norm": 0.32307562232017517,
      "learning_rate": 3.759147544321841e-05,
      "loss": 0.0804,
      "step": 39000
    },
    {
      "epoch": 0.7540758275743576,
      "grad_norm": 0.193039670586586,
      "learning_rate": 3.743238771588205e-05,
      "loss": 0.0805,
      "step": 39500
    },
    {
      "epoch": 0.7636210912145394,
      "grad_norm": 0.15327805280685425,
      "learning_rate": 3.727329998854568e-05,
      "loss": 0.0796,
      "step": 40000
    },
    {
      "epoch": 0.7731663548547211,
      "grad_norm": 0.25463736057281494,
      "learning_rate": 3.7114212261209325e-05,
      "loss": 0.0792,
      "step": 40500
    },
    {
      "epoch": 0.7827116184949028,
      "grad_norm": 0.19682000577449799,
      "learning_rate": 3.695512453387296e-05,
      "loss": 0.0777,
      "step": 41000
    },
    {
      "epoch": 0.7922568821350846,
      "grad_norm": 0.21646250784397125,
      "learning_rate": 3.67960368065366e-05,
      "loss": 0.0802,
      "step": 41500
    },
    {
      "epoch": 0.8018021457752663,
      "grad_norm": 0.19079755246639252,
      "learning_rate": 3.663694907920023e-05,
      "loss": 0.0757,
      "step": 42000
    },
    {
      "epoch": 0.811347409415448,
      "grad_norm": 0.2823275327682495,
      "learning_rate": 3.6477861351863875e-05,
      "loss": 0.0785,
      "step": 42500
    },
    {
      "epoch": 0.8208926730556299,
      "grad_norm": 0.19812747836112976,
      "learning_rate": 3.631877362452751e-05,
      "loss": 0.08,
      "step": 43000
    },
    {
      "epoch": 0.8304379366958116,
      "grad_norm": 0.1864033341407776,
      "learning_rate": 3.6159685897191146e-05,
      "loss": 0.0784,
      "step": 43500
    },
    {
      "epoch": 0.8399832003359933,
      "grad_norm": 0.1652858853340149,
      "learning_rate": 3.600059816985479e-05,
      "loss": 0.0788,
      "step": 44000
    },
    {
      "epoch": 0.849528463976175,
      "grad_norm": 0.20059335231781006,
      "learning_rate": 3.5841510442518424e-05,
      "loss": 0.0783,
      "step": 44500
    },
    {
      "epoch": 0.8590737276163568,
      "grad_norm": 0.2118292897939682,
      "learning_rate": 3.568242271518206e-05,
      "loss": 0.0799,
      "step": 45000
    },
    {
      "epoch": 0.8686189912565385,
      "grad_norm": 0.20373347401618958,
      "learning_rate": 3.5523334987845695e-05,
      "loss": 0.0771,
      "step": 45500
    },
    {
      "epoch": 0.8781642548967202,
      "grad_norm": 0.16109108924865723,
      "learning_rate": 3.536424726050934e-05,
      "loss": 0.0789,
      "step": 46000
    },
    {
      "epoch": 0.8877095185369019,
      "grad_norm": 0.24914981424808502,
      "learning_rate": 3.5205159533172974e-05,
      "loss": 0.0775,
      "step": 46500
    },
    {
      "epoch": 0.8972547821770838,
      "grad_norm": 0.1902075558900833,
      "learning_rate": 3.504607180583661e-05,
      "loss": 0.0763,
      "step": 47000
    },
    {
      "epoch": 0.9068000458172655,
      "grad_norm": 0.2666968107223511,
      "learning_rate": 3.488698407850025e-05,
      "loss": 0.0776,
      "step": 47500
    },
    {
      "epoch": 0.9163453094574472,
      "grad_norm": 0.24693559110164642,
      "learning_rate": 3.472789635116389e-05,
      "loss": 0.0761,
      "step": 48000
    },
    {
      "epoch": 0.925890573097629,
      "grad_norm": 0.3535774350166321,
      "learning_rate": 3.456880862382752e-05,
      "loss": 0.0782,
      "step": 48500
    },
    {
      "epoch": 0.9354358367378107,
      "grad_norm": 0.2471315562725067,
      "learning_rate": 3.4409720896491165e-05,
      "loss": 0.0773,
      "step": 49000
    },
    {
      "epoch": 0.9449811003779924,
      "grad_norm": 0.20493420958518982,
      "learning_rate": 3.42506331691548e-05,
      "loss": 0.0777,
      "step": 49500
    },
    {
      "epoch": 0.9545263640181741,
      "grad_norm": 0.21647632122039795,
      "learning_rate": 3.409154544181844e-05,
      "loss": 0.0774,
      "step": 50000
    },
    {
      "epoch": 0.964071627658356,
      "grad_norm": 0.13765031099319458,
      "learning_rate": 3.393245771448207e-05,
      "loss": 0.0768,
      "step": 50500
    },
    {
      "epoch": 0.9736168912985377,
      "grad_norm": 0.2393442988395691,
      "learning_rate": 3.3773369987145715e-05,
      "loss": 0.0781,
      "step": 51000
    },
    {
      "epoch": 0.9831621549387194,
      "grad_norm": 0.19205887615680695,
      "learning_rate": 3.361428225980935e-05,
      "loss": 0.0778,
      "step": 51500
    },
    {
      "epoch": 0.9927074185789011,
      "grad_norm": 0.2679242193698883,
      "learning_rate": 3.3455194532472986e-05,
      "loss": 0.0749,
      "step": 52000
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.06205110624432564,
      "eval_runtime": 2962.2253,
      "eval_samples_per_second": 141.467,
      "eval_steps_per_second": 17.683,
      "step": 52382
    },
    {
      "epoch": 1.002252682219083,
      "grad_norm": 0.15415294468402863,
      "learning_rate": 3.329610680513663e-05,
      "loss": 0.0754,
      "step": 52500
    },
    {
      "epoch": 1.0117979458592645,
      "grad_norm": 0.17333900928497314,
      "learning_rate": 3.3137019077800264e-05,
      "loss": 0.0768,
      "step": 53000
    },
    {
      "epoch": 1.0213432094994463,
      "grad_norm": 0.20886953175067902,
      "learning_rate": 3.29779313504639e-05,
      "loss": 0.0749,
      "step": 53500
    },
    {
      "epoch": 1.0308884731396282,
      "grad_norm": 0.2340811938047409,
      "learning_rate": 3.2818843623127536e-05,
      "loss": 0.0763,
      "step": 54000
    },
    {
      "epoch": 1.0404337367798098,
      "grad_norm": 0.20888637006282806,
      "learning_rate": 3.265975589579118e-05,
      "loss": 0.0738,
      "step": 54500
    },
    {
      "epoch": 1.0499790004199916,
      "grad_norm": 0.314496248960495,
      "learning_rate": 3.2500668168454814e-05,
      "loss": 0.0768,
      "step": 55000
    },
    {
      "epoch": 1.0595242640601734,
      "grad_norm": 0.1938590705394745,
      "learning_rate": 3.234158044111845e-05,
      "loss": 0.0735,
      "step": 55500
    },
    {
      "epoch": 1.069069527700355,
      "grad_norm": 0.24795274436473846,
      "learning_rate": 3.218249271378209e-05,
      "loss": 0.0742,
      "step": 56000
    },
    {
      "epoch": 1.0786147913405368,
      "grad_norm": 0.25025278329849243,
      "learning_rate": 3.202340498644573e-05,
      "loss": 0.0734,
      "step": 56500
    },
    {
      "epoch": 1.0881600549807187,
      "grad_norm": 0.21380215883255005,
      "learning_rate": 3.186431725910936e-05,
      "loss": 0.0741,
      "step": 57000
    },
    {
      "epoch": 1.0977053186209003,
      "grad_norm": 0.30150651931762695,
      "learning_rate": 3.1705229531773e-05,
      "loss": 0.0763,
      "step": 57500
    },
    {
      "epoch": 1.107250582261082,
      "grad_norm": 0.14467932283878326,
      "learning_rate": 3.154614180443664e-05,
      "loss": 0.0736,
      "step": 58000
    },
    {
      "epoch": 1.116795845901264,
      "grad_norm": 0.1959609091281891,
      "learning_rate": 3.138705407710028e-05,
      "loss": 0.0716,
      "step": 58500
    },
    {
      "epoch": 1.1263411095414455,
      "grad_norm": 0.19721999764442444,
      "learning_rate": 3.122796634976391e-05,
      "loss": 0.0746,
      "step": 59000
    },
    {
      "epoch": 1.1358863731816273,
      "grad_norm": 0.17729046940803528,
      "learning_rate": 3.1068878622427555e-05,
      "loss": 0.0748,
      "step": 59500
    },
    {
      "epoch": 1.145431636821809,
      "grad_norm": 0.20530292391777039,
      "learning_rate": 3.090979089509119e-05,
      "loss": 0.0746,
      "step": 60000
    },
    {
      "epoch": 1.1549769004619908,
      "grad_norm": 0.2908259630203247,
      "learning_rate": 3.075070316775483e-05,
      "loss": 0.0737,
      "step": 60500
    },
    {
      "epoch": 1.1645221641021726,
      "grad_norm": 0.1508679986000061,
      "learning_rate": 3.059161544041846e-05,
      "loss": 0.0702,
      "step": 61000
    },
    {
      "epoch": 1.1740674277423542,
      "grad_norm": 0.2367575615644455,
      "learning_rate": 3.0432527713082104e-05,
      "loss": 0.0706,
      "step": 61500
    },
    {
      "epoch": 1.183612691382536,
      "grad_norm": 0.2248425930738449,
      "learning_rate": 3.027343998574574e-05,
      "loss": 0.0715,
      "step": 62000
    },
    {
      "epoch": 1.1931579550227178,
      "grad_norm": 0.20640505850315094,
      "learning_rate": 3.011435225840938e-05,
      "loss": 0.0729,
      "step": 62500
    },
    {
      "epoch": 1.2027032186628994,
      "grad_norm": 0.19802680611610413,
      "learning_rate": 2.9955264531073018e-05,
      "loss": 0.0732,
      "step": 63000
    },
    {
      "epoch": 1.2122484823030812,
      "grad_norm": 0.25850316882133484,
      "learning_rate": 2.9796176803736654e-05,
      "loss": 0.0728,
      "step": 63500
    },
    {
      "epoch": 1.221793745943263,
      "grad_norm": 0.2642975151538849,
      "learning_rate": 2.9637089076400293e-05,
      "loss": 0.0742,
      "step": 64000
    },
    {
      "epoch": 1.2313390095834447,
      "grad_norm": 0.16998256742954254,
      "learning_rate": 2.947800134906393e-05,
      "loss": 0.0729,
      "step": 64500
    },
    {
      "epoch": 1.2408842732236265,
      "grad_norm": 0.15019632875919342,
      "learning_rate": 2.9318913621727567e-05,
      "loss": 0.0735,
      "step": 65000
    },
    {
      "epoch": 1.250429536863808,
      "grad_norm": 0.22129566967487335,
      "learning_rate": 2.9159825894391203e-05,
      "loss": 0.0717,
      "step": 65500
    },
    {
      "epoch": 1.25997480050399,
      "grad_norm": 0.18082797527313232,
      "learning_rate": 2.9000738167054842e-05,
      "loss": 0.0727,
      "step": 66000
    },
    {
      "epoch": 1.2695200641441717,
      "grad_norm": 0.1991959810256958,
      "learning_rate": 2.884165043971848e-05,
      "loss": 0.0704,
      "step": 66500
    },
    {
      "epoch": 1.2790653277843533,
      "grad_norm": 0.19181276857852936,
      "learning_rate": 2.8682562712382117e-05,
      "loss": 0.071,
      "step": 67000
    },
    {
      "epoch": 1.2886105914245352,
      "grad_norm": 0.17726436257362366,
      "learning_rate": 2.8523474985045756e-05,
      "loss": 0.0723,
      "step": 67500
    },
    {
      "epoch": 1.2981558550647168,
      "grad_norm": 0.2844589352607727,
      "learning_rate": 2.836438725770939e-05,
      "loss": 0.0709,
      "step": 68000
    },
    {
      "epoch": 1.3077011187048986,
      "grad_norm": 0.2432163655757904,
      "learning_rate": 2.820529953037303e-05,
      "loss": 0.0729,
      "step": 68500
    },
    {
      "epoch": 1.3172463823450804,
      "grad_norm": 0.17021647095680237,
      "learning_rate": 2.804621180303667e-05,
      "loss": 0.0717,
      "step": 69000
    },
    {
      "epoch": 1.3267916459852622,
      "grad_norm": 0.2416570633649826,
      "learning_rate": 2.7887124075700305e-05,
      "loss": 0.0734,
      "step": 69500
    },
    {
      "epoch": 1.3363369096254438,
      "grad_norm": 0.14522892236709595,
      "learning_rate": 2.7728036348363944e-05,
      "loss": 0.0722,
      "step": 70000
    },
    {
      "epoch": 1.3458821732656256,
      "grad_norm": 0.135999858379364,
      "learning_rate": 2.756894862102758e-05,
      "loss": 0.0692,
      "step": 70500
    },
    {
      "epoch": 1.3554274369058072,
      "grad_norm": 0.28028568625450134,
      "learning_rate": 2.740986089369122e-05,
      "loss": 0.0705,
      "step": 71000
    },
    {
      "epoch": 1.364972700545989,
      "grad_norm": 0.24267065525054932,
      "learning_rate": 2.7250773166354855e-05,
      "loss": 0.0707,
      "step": 71500
    },
    {
      "epoch": 1.374517964186171,
      "grad_norm": 0.14504334330558777,
      "learning_rate": 2.7091685439018494e-05,
      "loss": 0.0728,
      "step": 72000
    },
    {
      "epoch": 1.3840632278263525,
      "grad_norm": 0.18618689477443695,
      "learning_rate": 2.6932597711682133e-05,
      "loss": 0.0725,
      "step": 72500
    },
    {
      "epoch": 1.3936084914665343,
      "grad_norm": 0.3039734661579132,
      "learning_rate": 2.677350998434577e-05,
      "loss": 0.0711,
      "step": 73000
    },
    {
      "epoch": 1.403153755106716,
      "grad_norm": 0.20483805239200592,
      "learning_rate": 2.6614422257009407e-05,
      "loss": 0.0707,
      "step": 73500
    },
    {
      "epoch": 1.4126990187468977,
      "grad_norm": 0.19408264756202698,
      "learning_rate": 2.6455334529673043e-05,
      "loss": 0.071,
      "step": 74000
    },
    {
      "epoch": 1.4222442823870796,
      "grad_norm": 0.1710851788520813,
      "learning_rate": 2.6296246802336682e-05,
      "loss": 0.0721,
      "step": 74500
    },
    {
      "epoch": 1.4317895460272614,
      "grad_norm": 0.17207591235637665,
      "learning_rate": 2.6137159075000318e-05,
      "loss": 0.0719,
      "step": 75000
    },
    {
      "epoch": 1.441334809667443,
      "grad_norm": 0.14477847516536713,
      "learning_rate": 2.5978071347663957e-05,
      "loss": 0.0729,
      "step": 75500
    },
    {
      "epoch": 1.4508800733076248,
      "grad_norm": 0.22630733251571655,
      "learning_rate": 2.5818983620327596e-05,
      "loss": 0.0723,
      "step": 76000
    },
    {
      "epoch": 1.4604253369478064,
      "grad_norm": 0.23720672726631165,
      "learning_rate": 2.565989589299123e-05,
      "loss": 0.071,
      "step": 76500
    },
    {
      "epoch": 1.4699706005879882,
      "grad_norm": 0.2085345983505249,
      "learning_rate": 2.550080816565487e-05,
      "loss": 0.0704,
      "step": 77000
    },
    {
      "epoch": 1.47951586422817,
      "grad_norm": 0.2335543930530548,
      "learning_rate": 2.5341720438318506e-05,
      "loss": 0.0705,
      "step": 77500
    },
    {
      "epoch": 1.4890611278683517,
      "grad_norm": 0.20013993978500366,
      "learning_rate": 2.5182632710982145e-05,
      "loss": 0.0745,
      "step": 78000
    },
    {
      "epoch": 1.4986063915085335,
      "grad_norm": 0.18713338673114777,
      "learning_rate": 2.502354498364578e-05,
      "loss": 0.0708,
      "step": 78500
    },
    {
      "epoch": 1.508151655148715,
      "grad_norm": 0.23054322600364685,
      "learning_rate": 2.486445725630942e-05,
      "loss": 0.0735,
      "step": 79000
    },
    {
      "epoch": 1.517696918788897,
      "grad_norm": 0.15163318812847137,
      "learning_rate": 2.470536952897306e-05,
      "loss": 0.0705,
      "step": 79500
    },
    {
      "epoch": 1.5272421824290787,
      "grad_norm": 0.2042597383260727,
      "learning_rate": 2.4546281801636695e-05,
      "loss": 0.0697,
      "step": 80000
    },
    {
      "epoch": 1.5367874460692605,
      "grad_norm": 0.1413196176290512,
      "learning_rate": 2.4387194074300334e-05,
      "loss": 0.0722,
      "step": 80500
    },
    {
      "epoch": 1.5463327097094421,
      "grad_norm": 0.20042690634727478,
      "learning_rate": 2.4228106346963973e-05,
      "loss": 0.0713,
      "step": 81000
    },
    {
      "epoch": 1.555877973349624,
      "grad_norm": 0.14281877875328064,
      "learning_rate": 2.406901861962761e-05,
      "loss": 0.0685,
      "step": 81500
    },
    {
      "epoch": 1.5654232369898056,
      "grad_norm": 0.13086220622062683,
      "learning_rate": 2.3909930892291247e-05,
      "loss": 0.0712,
      "step": 82000
    },
    {
      "epoch": 1.5749685006299874,
      "grad_norm": 0.2397587150335312,
      "learning_rate": 2.3750843164954883e-05,
      "loss": 0.071,
      "step": 82500
    },
    {
      "epoch": 1.5845137642701692,
      "grad_norm": 0.23021221160888672,
      "learning_rate": 2.3591755437618522e-05,
      "loss": 0.0702,
      "step": 83000
    },
    {
      "epoch": 1.594059027910351,
      "grad_norm": 0.1667807251214981,
      "learning_rate": 2.3432667710282158e-05,
      "loss": 0.0724,
      "step": 83500
    },
    {
      "epoch": 1.6036042915505326,
      "grad_norm": 0.27981993556022644,
      "learning_rate": 2.3273579982945797e-05,
      "loss": 0.0688,
      "step": 84000
    },
    {
      "epoch": 1.6131495551907142,
      "grad_norm": 0.21935231983661652,
      "learning_rate": 2.3114492255609436e-05,
      "loss": 0.0699,
      "step": 84500
    },
    {
      "epoch": 1.622694818830896,
      "grad_norm": 0.302864670753479,
      "learning_rate": 2.295540452827307e-05,
      "loss": 0.0743,
      "step": 85000
    },
    {
      "epoch": 1.6322400824710779,
      "grad_norm": 0.12966373562812805,
      "learning_rate": 2.279631680093671e-05,
      "loss": 0.0694,
      "step": 85500
    },
    {
      "epoch": 1.6417853461112597,
      "grad_norm": 0.2647520899772644,
      "learning_rate": 2.2637229073600346e-05,
      "loss": 0.0703,
      "step": 86000
    },
    {
      "epoch": 1.6513306097514413,
      "grad_norm": 0.14113828539848328,
      "learning_rate": 2.2478141346263985e-05,
      "loss": 0.0701,
      "step": 86500
    },
    {
      "epoch": 1.6608758733916231,
      "grad_norm": 0.3463307321071625,
      "learning_rate": 2.231905361892762e-05,
      "loss": 0.0727,
      "step": 87000
    },
    {
      "epoch": 1.6704211370318047,
      "grad_norm": 0.2147776335477829,
      "learning_rate": 2.215996589159126e-05,
      "loss": 0.0685,
      "step": 87500
    },
    {
      "epoch": 1.6799664006719865,
      "grad_norm": 0.127351313829422,
      "learning_rate": 2.20008781642549e-05,
      "loss": 0.0695,
      "step": 88000
    },
    {
      "epoch": 1.6895116643121684,
      "grad_norm": 0.20107944309711456,
      "learning_rate": 2.1841790436918535e-05,
      "loss": 0.0686,
      "step": 88500
    },
    {
      "epoch": 1.6990569279523502,
      "grad_norm": 0.18361318111419678,
      "learning_rate": 2.1682702709582174e-05,
      "loss": 0.0693,
      "step": 89000
    },
    {
      "epoch": 1.7086021915925318,
      "grad_norm": 0.11645103245973587,
      "learning_rate": 2.152361498224581e-05,
      "loss": 0.0695,
      "step": 89500
    },
    {
      "epoch": 1.7181474552327134,
      "grad_norm": 0.28485146164894104,
      "learning_rate": 2.136452725490945e-05,
      "loss": 0.0712,
      "step": 90000
    },
    {
      "epoch": 1.7276927188728952,
      "grad_norm": 0.22761942446231842,
      "learning_rate": 2.1205439527573087e-05,
      "loss": 0.0684,
      "step": 90500
    },
    {
      "epoch": 1.737237982513077,
      "grad_norm": 0.29645392298698425,
      "learning_rate": 2.1046351800236723e-05,
      "loss": 0.0703,
      "step": 91000
    },
    {
      "epoch": 1.7467832461532589,
      "grad_norm": 0.16355185210704803,
      "learning_rate": 2.0887264072900362e-05,
      "loss": 0.0719,
      "step": 91500
    },
    {
      "epoch": 1.7563285097934405,
      "grad_norm": 0.22304940223693848,
      "learning_rate": 2.0728176345563998e-05,
      "loss": 0.0694,
      "step": 92000
    },
    {
      "epoch": 1.7658737734336223,
      "grad_norm": 0.3032442629337311,
      "learning_rate": 2.0569088618227637e-05,
      "loss": 0.0696,
      "step": 92500
    },
    {
      "epoch": 1.7754190370738039,
      "grad_norm": 0.2057262510061264,
      "learning_rate": 2.0410000890891273e-05,
      "loss": 0.0699,
      "step": 93000
    },
    {
      "epoch": 1.7849643007139857,
      "grad_norm": 0.15735207498073578,
      "learning_rate": 2.025091316355491e-05,
      "loss": 0.0688,
      "step": 93500
    },
    {
      "epoch": 1.7945095643541675,
      "grad_norm": 0.47712382674217224,
      "learning_rate": 2.009182543621855e-05,
      "loss": 0.0713,
      "step": 94000
    },
    {
      "epoch": 1.8040548279943494,
      "grad_norm": 0.23195771872997284,
      "learning_rate": 1.9932737708882186e-05,
      "loss": 0.0701,
      "step": 94500
    },
    {
      "epoch": 1.813600091634531,
      "grad_norm": 0.1799042522907257,
      "learning_rate": 1.9773649981545825e-05,
      "loss": 0.0702,
      "step": 95000
    },
    {
      "epoch": 1.8231453552747126,
      "grad_norm": 0.1479894369840622,
      "learning_rate": 1.961456225420946e-05,
      "loss": 0.0699,
      "step": 95500
    },
    {
      "epoch": 1.8326906189148944,
      "grad_norm": 0.23071804642677307,
      "learning_rate": 1.94554745268731e-05,
      "loss": 0.0678,
      "step": 96000
    },
    {
      "epoch": 1.8422358825550762,
      "grad_norm": 0.1679968386888504,
      "learning_rate": 1.9296386799536736e-05,
      "loss": 0.0699,
      "step": 96500
    },
    {
      "epoch": 1.851781146195258,
      "grad_norm": 0.20125307142734528,
      "learning_rate": 1.9137299072200378e-05,
      "loss": 0.0684,
      "step": 97000
    },
    {
      "epoch": 1.8613264098354396,
      "grad_norm": 0.2188422679901123,
      "learning_rate": 1.8978211344864014e-05,
      "loss": 0.0672,
      "step": 97500
    },
    {
      "epoch": 1.8708716734756214,
      "grad_norm": 0.17413827776908875,
      "learning_rate": 1.881912361752765e-05,
      "loss": 0.0698,
      "step": 98000
    },
    {
      "epoch": 1.880416937115803,
      "grad_norm": 0.2736130654811859,
      "learning_rate": 1.866003589019129e-05,
      "loss": 0.0674,
      "step": 98500
    },
    {
      "epoch": 1.8899622007559849,
      "grad_norm": 0.13052032887935638,
      "learning_rate": 1.8500948162854924e-05,
      "loss": 0.0681,
      "step": 99000
    },
    {
      "epoch": 1.8995074643961667,
      "grad_norm": 0.17302410304546356,
      "learning_rate": 1.8341860435518563e-05,
      "loss": 0.0702,
      "step": 99500
    },
    {
      "epoch": 1.9090527280363485,
      "grad_norm": 0.23504671454429626,
      "learning_rate": 1.81827727081822e-05,
      "loss": 0.0695,
      "step": 100000
    },
    {
      "epoch": 1.9185979916765301,
      "grad_norm": 0.30882078409194946,
      "learning_rate": 1.802368498084584e-05,
      "loss": 0.0682,
      "step": 100500
    },
    {
      "epoch": 1.9281432553167117,
      "grad_norm": 0.14945708215236664,
      "learning_rate": 1.7864597253509477e-05,
      "loss": 0.0684,
      "step": 101000
    },
    {
      "epoch": 1.9376885189568935,
      "grad_norm": 0.29783111810684204,
      "learning_rate": 1.7705509526173113e-05,
      "loss": 0.07,
      "step": 101500
    },
    {
      "epoch": 1.9472337825970754,
      "grad_norm": 0.21389110386371613,
      "learning_rate": 1.754642179883675e-05,
      "loss": 0.0681,
      "step": 102000
    },
    {
      "epoch": 1.9567790462372572,
      "grad_norm": 0.24669872224330902,
      "learning_rate": 1.7387334071500387e-05,
      "loss": 0.0684,
      "step": 102500
    },
    {
      "epoch": 1.9663243098774388,
      "grad_norm": 0.14676381647586823,
      "learning_rate": 1.7228246344164026e-05,
      "loss": 0.0677,
      "step": 103000
    },
    {
      "epoch": 1.9758695735176206,
      "grad_norm": 0.17150132358074188,
      "learning_rate": 1.7069158616827662e-05,
      "loss": 0.0649,
      "step": 103500
    },
    {
      "epoch": 1.9854148371578022,
      "grad_norm": 0.12601633369922638,
      "learning_rate": 1.6910070889491304e-05,
      "loss": 0.0686,
      "step": 104000
    },
    {
      "epoch": 1.994960100797984,
      "grad_norm": 0.2020021229982376,
      "learning_rate": 1.675098316215494e-05,
      "loss": 0.0688,
      "step": 104500
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.05590543523430824,
      "eval_runtime": 2194.7519,
      "eval_samples_per_second": 190.935,
      "eval_steps_per_second": 23.867,
      "step": 104764
    },
    {
      "epoch": 2.004505364438166,
      "grad_norm": 0.12146277725696564,
      "learning_rate": 1.6591895434818576e-05,
      "loss": 0.0682,
      "step": 105000
    },
    {
      "epoch": 2.0140506280783477,
      "grad_norm": 0.28932520747184753,
      "learning_rate": 1.6432807707482215e-05,
      "loss": 0.0685,
      "step": 105500
    },
    {
      "epoch": 2.023595891718529,
      "grad_norm": 0.14079688489437103,
      "learning_rate": 1.627371998014585e-05,
      "loss": 0.0666,
      "step": 106000
    },
    {
      "epoch": 2.033141155358711,
      "grad_norm": 0.367326557636261,
      "learning_rate": 1.611463225280949e-05,
      "loss": 0.0661,
      "step": 106500
    },
    {
      "epoch": 2.0426864189988927,
      "grad_norm": 0.13551418483257294,
      "learning_rate": 1.595554452547313e-05,
      "loss": 0.0659,
      "step": 107000
    },
    {
      "epoch": 2.0522316826390745,
      "grad_norm": 0.1333649456501007,
      "learning_rate": 1.5796456798136768e-05,
      "loss": 0.0635,
      "step": 107500
    },
    {
      "epoch": 2.0617769462792563,
      "grad_norm": 0.24020074307918549,
      "learning_rate": 1.5637369070800403e-05,
      "loss": 0.0689,
      "step": 108000
    },
    {
      "epoch": 2.071322209919438,
      "grad_norm": 0.19455638527870178,
      "learning_rate": 1.5478281343464042e-05,
      "loss": 0.0654,
      "step": 108500
    },
    {
      "epoch": 2.0808674735596195,
      "grad_norm": 0.17571023106575012,
      "learning_rate": 1.5319193616127678e-05,
      "loss": 0.067,
      "step": 109000
    },
    {
      "epoch": 2.0904127371998014,
      "grad_norm": 0.22933900356292725,
      "learning_rate": 1.5160105888791315e-05,
      "loss": 0.0677,
      "step": 109500
    },
    {
      "epoch": 2.099958000839983,
      "grad_norm": 0.21412496268749237,
      "learning_rate": 1.5001018161454953e-05,
      "loss": 0.0653,
      "step": 110000
    },
    {
      "epoch": 2.109503264480165,
      "grad_norm": 0.14166033267974854,
      "learning_rate": 1.4841930434118592e-05,
      "loss": 0.067,
      "step": 110500
    },
    {
      "epoch": 2.119048528120347,
      "grad_norm": 0.16491222381591797,
      "learning_rate": 1.4682842706782229e-05,
      "loss": 0.067,
      "step": 111000
    },
    {
      "epoch": 2.1285937917605287,
      "grad_norm": 0.38815197348594666,
      "learning_rate": 1.4523754979445866e-05,
      "loss": 0.0673,
      "step": 111500
    },
    {
      "epoch": 2.13813905540071,
      "grad_norm": 0.15701965987682343,
      "learning_rate": 1.4364667252109504e-05,
      "loss": 0.0675,
      "step": 112000
    },
    {
      "epoch": 2.147684319040892,
      "grad_norm": 0.161844864487648,
      "learning_rate": 1.4205579524773141e-05,
      "loss": 0.0661,
      "step": 112500
    },
    {
      "epoch": 2.1572295826810737,
      "grad_norm": 0.15155132114887238,
      "learning_rate": 1.4046491797436778e-05,
      "loss": 0.0682,
      "step": 113000
    },
    {
      "epoch": 2.1667748463212555,
      "grad_norm": 0.2592942714691162,
      "learning_rate": 1.3887404070100417e-05,
      "loss": 0.0653,
      "step": 113500
    },
    {
      "epoch": 2.1763201099614373,
      "grad_norm": 0.28158867359161377,
      "learning_rate": 1.3728316342764055e-05,
      "loss": 0.0666,
      "step": 114000
    },
    {
      "epoch": 2.1858653736016187,
      "grad_norm": 0.18797220289707184,
      "learning_rate": 1.3569228615427692e-05,
      "loss": 0.0662,
      "step": 114500
    },
    {
      "epoch": 2.1954106372418005,
      "grad_norm": 0.148302361369133,
      "learning_rate": 1.341014088809133e-05,
      "loss": 0.0645,
      "step": 115000
    },
    {
      "epoch": 2.2049559008819823,
      "grad_norm": 0.24718382954597473,
      "learning_rate": 1.3251053160754967e-05,
      "loss": 0.0689,
      "step": 115500
    },
    {
      "epoch": 2.214501164522164,
      "grad_norm": 0.15963028371334076,
      "learning_rate": 1.3091965433418604e-05,
      "loss": 0.0681,
      "step": 116000
    },
    {
      "epoch": 2.224046428162346,
      "grad_norm": 0.18347615003585815,
      "learning_rate": 1.2932877706082242e-05,
      "loss": 0.0668,
      "step": 116500
    },
    {
      "epoch": 2.233591691802528,
      "grad_norm": 0.22618253529071808,
      "learning_rate": 1.2773789978745882e-05,
      "loss": 0.066,
      "step": 117000
    },
    {
      "epoch": 2.243136955442709,
      "grad_norm": 0.1686614751815796,
      "learning_rate": 1.2614702251409518e-05,
      "loss": 0.0671,
      "step": 117500
    },
    {
      "epoch": 2.252682219082891,
      "grad_norm": 0.16857685148715973,
      "learning_rate": 1.2455614524073155e-05,
      "loss": 0.0661,
      "step": 118000
    },
    {
      "epoch": 2.262227482723073,
      "grad_norm": 0.16529534757137299,
      "learning_rate": 1.2296526796736793e-05,
      "loss": 0.0682,
      "step": 118500
    },
    {
      "epoch": 2.2717727463632547,
      "grad_norm": 0.16159909963607788,
      "learning_rate": 1.213743906940043e-05,
      "loss": 0.0633,
      "step": 119000
    },
    {
      "epoch": 2.2813180100034365,
      "grad_norm": 0.21998220682144165,
      "learning_rate": 1.1978351342064069e-05,
      "loss": 0.0657,
      "step": 119500
    },
    {
      "epoch": 2.290863273643618,
      "grad_norm": 0.17180849611759186,
      "learning_rate": 1.1819263614727706e-05,
      "loss": 0.0652,
      "step": 120000
    },
    {
      "epoch": 2.3004085372837997,
      "grad_norm": 0.1809755116701126,
      "learning_rate": 1.1660175887391344e-05,
      "loss": 0.0655,
      "step": 120500
    },
    {
      "epoch": 2.3099538009239815,
      "grad_norm": 0.24473723769187927,
      "learning_rate": 1.1501088160054983e-05,
      "loss": 0.0654,
      "step": 121000
    },
    {
      "epoch": 2.3194990645641633,
      "grad_norm": 0.19695830345153809,
      "learning_rate": 1.1342000432718618e-05,
      "loss": 0.0669,
      "step": 121500
    },
    {
      "epoch": 2.329044328204345,
      "grad_norm": 0.3060252368450165,
      "learning_rate": 1.1182912705382256e-05,
      "loss": 0.0671,
      "step": 122000
    },
    {
      "epoch": 2.338589591844527,
      "grad_norm": 0.27458012104034424,
      "learning_rate": 1.1023824978045893e-05,
      "loss": 0.0659,
      "step": 122500
    },
    {
      "epoch": 2.3481348554847083,
      "grad_norm": 0.2356468290090561,
      "learning_rate": 1.0864737250709532e-05,
      "loss": 0.0684,
      "step": 123000
    },
    {
      "epoch": 2.35768011912489,
      "grad_norm": 0.14121589064598083,
      "learning_rate": 1.070564952337317e-05,
      "loss": 0.0667,
      "step": 123500
    },
    {
      "epoch": 2.367225382765072,
      "grad_norm": 0.14149704575538635,
      "learning_rate": 1.0546561796036807e-05,
      "loss": 0.0685,
      "step": 124000
    },
    {
      "epoch": 2.376770646405254,
      "grad_norm": 0.17538174986839294,
      "learning_rate": 1.0387474068700446e-05,
      "loss": 0.0683,
      "step": 124500
    },
    {
      "epoch": 2.3863159100454356,
      "grad_norm": 0.2351047396659851,
      "learning_rate": 1.0228386341364082e-05,
      "loss": 0.0686,
      "step": 125000
    },
    {
      "epoch": 2.395861173685617,
      "grad_norm": 0.1948687881231308,
      "learning_rate": 1.0069298614027719e-05,
      "loss": 0.0679,
      "step": 125500
    },
    {
      "epoch": 2.405406437325799,
      "grad_norm": 0.18905550241470337,
      "learning_rate": 9.910210886691358e-06,
      "loss": 0.0694,
      "step": 126000
    },
    {
      "epoch": 2.4149517009659807,
      "grad_norm": 0.24452544748783112,
      "learning_rate": 9.751123159354995e-06,
      "loss": 0.0645,
      "step": 126500
    },
    {
      "epoch": 2.4244969646061625,
      "grad_norm": 0.29706525802612305,
      "learning_rate": 9.592035432018633e-06,
      "loss": 0.0671,
      "step": 127000
    },
    {
      "epoch": 2.4340422282463443,
      "grad_norm": 0.15344585478305817,
      "learning_rate": 9.43294770468227e-06,
      "loss": 0.0649,
      "step": 127500
    },
    {
      "epoch": 2.443587491886526,
      "grad_norm": 0.18814122676849365,
      "learning_rate": 9.273859977345909e-06,
      "loss": 0.0685,
      "step": 128000
    },
    {
      "epoch": 2.4531327555267075,
      "grad_norm": 0.21132540702819824,
      "learning_rate": 9.114772250009546e-06,
      "loss": 0.0672,
      "step": 128500
    },
    {
      "epoch": 2.4626780191668893,
      "grad_norm": 0.13925401866436005,
      "learning_rate": 8.955684522673182e-06,
      "loss": 0.0668,
      "step": 129000
    },
    {
      "epoch": 2.472223282807071,
      "grad_norm": 0.16900040209293365,
      "learning_rate": 8.796596795336821e-06,
      "loss": 0.0679,
      "step": 129500
    },
    {
      "epoch": 2.481768546447253,
      "grad_norm": 0.2516944706439972,
      "learning_rate": 8.637509068000458e-06,
      "loss": 0.0657,
      "step": 130000
    },
    {
      "epoch": 2.491313810087435,
      "grad_norm": 0.13002707064151764,
      "learning_rate": 8.478421340664096e-06,
      "loss": 0.0661,
      "step": 130500
    },
    {
      "epoch": 2.500859073727616,
      "grad_norm": 0.25434422492980957,
      "learning_rate": 8.319333613327735e-06,
      "loss": 0.0681,
      "step": 131000
    },
    {
      "epoch": 2.510404337367798,
      "grad_norm": 0.17282001674175262,
      "learning_rate": 8.160245885991372e-06,
      "loss": 0.066,
      "step": 131500
    },
    {
      "epoch": 2.51994960100798,
      "grad_norm": 0.2363918572664261,
      "learning_rate": 8.00115815865501e-06,
      "loss": 0.0645,
      "step": 132000
    },
    {
      "epoch": 2.5294948646481616,
      "grad_norm": 0.1765112578868866,
      "learning_rate": 7.842070431318647e-06,
      "loss": 0.0644,
      "step": 132500
    },
    {
      "epoch": 2.5390401282883435,
      "grad_norm": 0.24133892357349396,
      "learning_rate": 7.682982703982284e-06,
      "loss": 0.0666,
      "step": 133000
    },
    {
      "epoch": 2.5485853919285253,
      "grad_norm": 0.1304800659418106,
      "learning_rate": 7.5238949766459216e-06,
      "loss": 0.0671,
      "step": 133500
    },
    {
      "epoch": 2.5581306555687067,
      "grad_norm": 0.2026924192905426,
      "learning_rate": 7.364807249309559e-06,
      "loss": 0.0645,
      "step": 134000
    },
    {
      "epoch": 2.5676759192088885,
      "grad_norm": 0.44343626499176025,
      "learning_rate": 7.205719521973198e-06,
      "loss": 0.0681,
      "step": 134500
    },
    {
      "epoch": 2.5772211828490703,
      "grad_norm": 0.15033793449401855,
      "learning_rate": 7.0466317946368345e-06,
      "loss": 0.0668,
      "step": 135000
    },
    {
      "epoch": 2.586766446489252,
      "grad_norm": 0.1920522302389145,
      "learning_rate": 6.887544067300472e-06,
      "loss": 0.0646,
      "step": 135500
    },
    {
      "epoch": 2.5963117101294335,
      "grad_norm": 0.20473156869411469,
      "learning_rate": 6.728456339964111e-06,
      "loss": 0.0658,
      "step": 136000
    },
    {
      "epoch": 2.6058569737696153,
      "grad_norm": 0.15386730432510376,
      "learning_rate": 6.569368612627748e-06,
      "loss": 0.0672,
      "step": 136500
    },
    {
      "epoch": 2.615402237409797,
      "grad_norm": 0.17084334790706635,
      "learning_rate": 6.410280885291385e-06,
      "loss": 0.0658,
      "step": 137000
    },
    {
      "epoch": 2.624947501049979,
      "grad_norm": 0.1527249813079834,
      "learning_rate": 6.251193157955024e-06,
      "loss": 0.0639,
      "step": 137500
    },
    {
      "epoch": 2.634492764690161,
      "grad_norm": 0.26519688963890076,
      "learning_rate": 6.092105430618661e-06,
      "loss": 0.0669,
      "step": 138000
    },
    {
      "epoch": 2.6440380283303426,
      "grad_norm": 0.15747873485088348,
      "learning_rate": 5.9330177032822984e-06,
      "loss": 0.0665,
      "step": 138500
    },
    {
      "epoch": 2.6535832919705244,
      "grad_norm": 0.18285126984119415,
      "learning_rate": 5.773929975945936e-06,
      "loss": 0.0648,
      "step": 139000
    },
    {
      "epoch": 2.663128555610706,
      "grad_norm": 0.18260793387889862,
      "learning_rate": 5.614842248609573e-06,
      "loss": 0.0678,
      "step": 139500
    },
    {
      "epoch": 2.6726738192508877,
      "grad_norm": 0.1285899579524994,
      "learning_rate": 5.455754521273211e-06,
      "loss": 0.0662,
      "step": 140000
    },
    {
      "epoch": 2.6822190828910695,
      "grad_norm": 0.09878137707710266,
      "learning_rate": 5.296666793936849e-06,
      "loss": 0.066,
      "step": 140500
    },
    {
      "epoch": 2.6917643465312513,
      "grad_norm": 0.16448061168193817,
      "learning_rate": 5.137579066600486e-06,
      "loss": 0.0673,
      "step": 141000
    },
    {
      "epoch": 2.7013096101714327,
      "grad_norm": 0.22216899693012238,
      "learning_rate": 4.978491339264124e-06,
      "loss": 0.0675,
      "step": 141500
    },
    {
      "epoch": 2.7108548738116145,
      "grad_norm": 0.14296844601631165,
      "learning_rate": 4.819403611927762e-06,
      "loss": 0.0654,
      "step": 142000
    },
    {
      "epoch": 2.7204001374517963,
      "grad_norm": 0.23392030596733093,
      "learning_rate": 4.660315884591399e-06,
      "loss": 0.0693,
      "step": 142500
    },
    {
      "epoch": 2.729945401091978,
      "grad_norm": 0.17782235145568848,
      "learning_rate": 4.501228157255037e-06,
      "loss": 0.0649,
      "step": 143000
    },
    {
      "epoch": 2.73949066473216,
      "grad_norm": 0.13513213396072388,
      "learning_rate": 4.3421404299186745e-06,
      "loss": 0.0641,
      "step": 143500
    },
    {
      "epoch": 2.749035928372342,
      "grad_norm": 0.26348763704299927,
      "learning_rate": 4.183052702582313e-06,
      "loss": 0.0649,
      "step": 144000
    },
    {
      "epoch": 2.7585811920125236,
      "grad_norm": 0.1953762024641037,
      "learning_rate": 4.023964975245949e-06,
      "loss": 0.0658,
      "step": 144500
    },
    {
      "epoch": 2.768126455652705,
      "grad_norm": 0.1738860309123993,
      "learning_rate": 3.864877247909587e-06,
      "loss": 0.0668,
      "step": 145000
    },
    {
      "epoch": 2.777671719292887,
      "grad_norm": 0.21053732931613922,
      "learning_rate": 3.705789520573225e-06,
      "loss": 0.0663,
      "step": 145500
    },
    {
      "epoch": 2.7872169829330686,
      "grad_norm": 0.18024025857448578,
      "learning_rate": 3.5467017932368625e-06,
      "loss": 0.0669,
      "step": 146000
    },
    {
      "epoch": 2.7967622465732505,
      "grad_norm": 0.181243896484375,
      "learning_rate": 3.3876140659005003e-06,
      "loss": 0.066,
      "step": 146500
    },
    {
      "epoch": 2.806307510213432,
      "grad_norm": 0.1390438675880432,
      "learning_rate": 3.2285263385641385e-06,
      "loss": 0.0644,
      "step": 147000
    },
    {
      "epoch": 2.8158527738536137,
      "grad_norm": 0.20229075849056244,
      "learning_rate": 3.0694386112277754e-06,
      "loss": 0.0662,
      "step": 147500
    },
    {
      "epoch": 2.8253980374937955,
      "grad_norm": 0.1724521368741989,
      "learning_rate": 2.910350883891413e-06,
      "loss": 0.0638,
      "step": 148000
    },
    {
      "epoch": 2.8349433011339773,
      "grad_norm": 0.14130213856697083,
      "learning_rate": 2.751263156555051e-06,
      "loss": 0.0649,
      "step": 148500
    },
    {
      "epoch": 2.844488564774159,
      "grad_norm": 0.1455622911453247,
      "learning_rate": 2.5921754292186887e-06,
      "loss": 0.0663,
      "step": 149000
    },
    {
      "epoch": 2.854033828414341,
      "grad_norm": 0.12601163983345032,
      "learning_rate": 2.433087701882326e-06,
      "loss": 0.0666,
      "step": 149500
    },
    {
      "epoch": 2.8635790920545228,
      "grad_norm": 0.2106322944164276,
      "learning_rate": 2.273999974545964e-06,
      "loss": 0.0658,
      "step": 150000
    },
    {
      "epoch": 2.873124355694704,
      "grad_norm": 0.15053346753120422,
      "learning_rate": 2.114912247209601e-06,
      "loss": 0.0676,
      "step": 150500
    },
    {
      "epoch": 2.882669619334886,
      "grad_norm": 0.40987974405288696,
      "learning_rate": 1.955824519873239e-06,
      "loss": 0.0678,
      "step": 151000
    },
    {
      "epoch": 2.892214882975068,
      "grad_norm": 0.16368317604064941,
      "learning_rate": 1.7967367925368767e-06,
      "loss": 0.0691,
      "step": 151500
    },
    {
      "epoch": 2.9017601466152496,
      "grad_norm": 0.28403857350349426,
      "learning_rate": 1.6376490652005143e-06,
      "loss": 0.0655,
      "step": 152000
    },
    {
      "epoch": 2.911305410255431,
      "grad_norm": 0.15515701472759247,
      "learning_rate": 1.4785613378641519e-06,
      "loss": 0.0667,
      "step": 152500
    },
    {
      "epoch": 2.920850673895613,
      "grad_norm": 0.16092364490032196,
      "learning_rate": 1.3194736105277894e-06,
      "loss": 0.0668,
      "step": 153000
    },
    {
      "epoch": 2.9303959375357946,
      "grad_norm": 0.2725193500518799,
      "learning_rate": 1.160385883191427e-06,
      "loss": 0.0686,
      "step": 153500
    },
    {
      "epoch": 2.9399412011759765,
      "grad_norm": 0.15099088847637177,
      "learning_rate": 1.0012981558550648e-06,
      "loss": 0.0672,
      "step": 154000
    },
    {
      "epoch": 2.9494864648161583,
      "grad_norm": 0.2474730908870697,
      "learning_rate": 8.422104285187023e-07,
      "loss": 0.0673,
      "step": 154500
    },
    {
      "epoch": 2.95903172845634,
      "grad_norm": 0.4625778794288635,
      "learning_rate": 6.8312270118234e-07,
      "loss": 0.0636,
      "step": 155000
    },
    {
      "epoch": 2.968576992096522,
      "grad_norm": 0.12513747811317444,
      "learning_rate": 5.240349738459777e-07,
      "loss": 0.0672,
      "step": 155500
    },
    {
      "epoch": 2.9781222557367033,
      "grad_norm": 0.10181038081645966,
      "learning_rate": 3.6494724650961527e-07,
      "loss": 0.067,
      "step": 156000
    },
    {
      "epoch": 2.987667519376885,
      "grad_norm": 0.139970600605011,
      "learning_rate": 2.058595191732529e-07,
      "loss": 0.0659,
      "step": 156500
    },
    {
      "epoch": 2.997212783017067,
      "grad_norm": 0.21673786640167236,
      "learning_rate": 4.677179183689054e-08,
      "loss": 0.0642,
      "step": 157000
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.054192688316106796,
      "eval_runtime": 2218.4622,
      "eval_samples_per_second": 188.895,
      "eval_steps_per_second": 23.612,
      "step": 157146
    }
  ],
  "logging_steps": 500,
  "max_steps": 157146,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4.253684546823782e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
